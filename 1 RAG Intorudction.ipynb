{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5106e56c",
   "metadata": {},
   "source": [
    "# RAG from Scratch\n",
    "## Overview and Purpose\n",
    "This repository contains my study notes on Retrieval-Augmented Generation (RAG) systems, which combine retrieval and generation techniques to answer questions effectively. RAG systems retrieve relevant documents from a knowledge base and use them to generate answers, similar to how humans process information.\n",
    "\n",
    "It is designed to be super newbie-friendly, providing a clear understanding of RAG systems and their components for someone like me, who is totally new to this topic.\n",
    "\n",
    "## Workflow of human who wants to answer a question\n",
    "1. Collect information from the knowledge base.\n",
    "2. Reason about the information to find relevant documents.\n",
    "3. Combine the retrieved documents with the original query.\n",
    "4. Generate a final answer using the combined information.\n",
    "## Comparation between RAG and Human\n",
    "| Step | RAG System | Human |\n",
    "|------|------------|-------|\n",
    "| 1    | **[Retrieval]** Collects documents from a knowledge base | Collects information from various sources |\n",
    "| 2    | **[Retrieval]** Uses a retriever to find relevant documents | Reasons about the information to find relevant documents |\n",
    "| 3    | **[Generation]** Combines retrieved documents with the original query | Combines information with the original question |\n",
    "| 4    | **[Generation]** Generates an answer using a generator model | Generates an answer using reasoning and knowledge |\n",
    "\n",
    "## What traditional LLMs do not know?\n",
    "Traditional Large Language Models (LLMs) are trained on vast amounts of text data but do not have access to real-time or external knowledge bases. They can generate text based on patterns learned during training but may not provide accurate or up-to-date information for specific queries.\n",
    "\n",
    "### Private knowledge bases\n",
    "Company-specific documents or proprietary data, are not included in the training data of traditional LLMs. This means they cannot retrieve or utilize this information effectively.\n",
    "\n",
    "### Real-time information\n",
    "Traditional LLMs do not have the capability to access or retrieve real-time information from the internet. LLMs are trained on static datasets and do not update their knowledge base dynamically. This limits their ability to answer questions that require current or live data.\n",
    "\n",
    "### Hard to access information\n",
    "Information off-line or in specialized databases that are not part of the training data of traditional LLMs. This limits their ability to answer questions that require specific or niche knowledge.\n",
    "\n",
    "## Quick Fix \n",
    "TO PUT THE ANSWER IN THE PROMPT! \n",
    "\n",
    "This is basically what RAG does. It retrieves relevant documents and combines them with the original query to generate a more accurate answer. RAG is short for Retrieval-Augmented Generation, which is a technique that enhances the capabilities of traditional LLMs by integrating retrieval mechanisms.\n",
    "\n",
    "## Advantages of RAG\n",
    "1. **Access to Real-time Knowledge**: RAG systems can retrieve and utilize real-time information from external knowledge bases, making them more accurate and up-to-date compared to traditional LLMs.\n",
    "2. **Private Knowledge Bases**: RAG systems can access private knowledge bases, such as company-specific documents or proprietary data, allowing them to provide more relevant and context-specific answers.\n",
    "3. **Enhanced Accuracy**: By combining retrieval and generation techniques, RAG systems can generate more accurate and contextually relevant answers, improving the overall quality of responses.\n",
    "4. **Reduced Hallucination**: RAG systems can reduce the occurrence of hallucinations (incorrect or fabricated information) by grounding answers in retrieved documents, leading to more reliable outputs.\n",
    "5. **Source Citation**: RAG systems can provide citations or references to the retrieved documents, allowing users to verify the information and understand the context of the answer.\n",
    "\n",
    "## RAG System Components\n",
    "1. **Retriever**: A component that retrieves relevant documents from a knowledge base based on the input query.\n",
    "2. **Generator**: A component that generates an answer using the retrieved documents and the original query.\n",
    "3. **Knowledge Base**: A collection of documents or data that the retriever uses to find relevant information.\n",
    "4. **Query**: The input question or request for information that the RAG system processes to retrieve and generate an answer.   \n",
    "\n",
    "![RAG System Architecture](./resources/basic_flow_deepLearningAI.jpg)\n",
    "*Figure: RAG System Architecture - Snapshot from DeepLearning.AI*\n",
    "\n",
    "## Example of RAG Application\n",
    "Code generation is a common application of RAG systems. For example, when a developer asks a question about how to implement a specific feature, the RAG system retrieves relevant code snippets from a knowledge base and generates an answer that includes the necessary code. Moreover, LLMs or agents can access user's code so it can provide more tailored and accurate responses. In this case, the knowledge is the code snippets in the knowledge base, and the query is the developer's question about implementing a feature.\n",
    "\n",
    "Customer service is another application where RAG systems can retrieve relevant information from a knowledge base to answer customer queries effectively. For instance, if a customer asks about the return policy, the RAG system retrieves the relevant policy document and generates a response based on that information. In this case, the knowledge is the company's return policy document, and the query is the customer's question about the return policy.\n",
    "\n",
    "Q&A systems are also a common use case for RAG. When a user asks a question, the RAG system retrieves relevant documents from a knowledge base and generates an answer that combines the retrieved information with the original query.\n",
    "\n",
    "AI-assisted web search is another application where RAG systems can enhance search results by retrieving relevant documents from a knowledge base and generating answers that provide more context and information than traditional search engines.\n",
    "\n",
    "## Takeaways\n",
    "1. RAG enhances traditional LLMs by integrating retrieval mechanisms.\n",
    "2. It enables access to real-time and private knowledge bases.\n",
    "3. RAG is applicable in various domains, including code generation, customer service, Q&A systems, and AI-assisted web search.\n",
    "4. The components of a RAG system include a retriever, generator, knowledge base, and query.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9565caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy code for RAG\n",
    "\n",
    "# Step 1: Define a simple knowledge base\n",
    "knowledge_base = [\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"RAG stands for Retrieval-Augmented Generation.\",\n",
    "    \"Large Language Models can generate text.\"\n",
    "]\n",
    "\n",
    "# Step 2: Retriever - find relevant documents\n",
    "def retrieve(query, kb):\n",
    "    return [doc for doc in kb if query.lower() in doc.lower()]\n",
    "\n",
    "# Step 3: Generator - combine query and retrieved docs to generate answer\n",
    "def generate_answer(query, docs):\n",
    "    context = \" \".join(docs)\n",
    "    return f\"Q: {query}\\nA: {context}\"\n",
    "\n",
    "# Step 4: Example usage\n",
    "query = \"What is RAG?\"\n",
    "retrieved_docs = retrieve(\"RAG\", knowledge_base)\n",
    "answer = generate_answer(query, retrieved_docs)\n",
    "print(answer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
