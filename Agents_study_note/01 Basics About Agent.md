# Study Note: Basics About LLM Agent Task 2

## Definitions

- '智能体（Agent）'：课程里面提到的智能体被定义为任何能够通过传感器（Sensors）感知其所处环境（Environment），并自主地通过执行器（Actuators）采取行动（Action）以达成特定目标的实体。

- '环境（Environment）'：智能体所处的外部世界，智能体通过传感器感知环境的信息，并通过执行器影响环境。

- '传感器（Sensors）'：智能体用来感知环境的工具或机制，能够收集环境中的信息。这些信息随后被智能体用来做出决策。在编程环境下，传感器可以是API调用、数据库查询等。如果我有一些物理的机器人，传感器可以是摄像头、温度传感器等。

- '行动（Action）'：智能体通过执行器采取的具体行为或操作，以实现其目标。在编程环境下，行动可以是发送HTTP请求、更新数据库记录，做出决策等。如果是物理机器人，行动可以是移动、抓取物体等。

- '自主性（Autonomy）'：智能体能够独立地感知环境、做出决策并采取行动，而不需要持续的外部干预或指导。这个是我后续学习的重点。

- 'PEAS 模型'：Performance（性能）、Environment（环境）、Actuators（执行器）、Sensors（传感器），上面几个概念合起来，用于描述智能体的特性。 


- '交互协议 (Interaction Protocol) '：智能体与环境之间进行信息交换和互动的规则和方式。

这个结构通常包含两个核心部分：

>Thought (思考)：这是智能体内部决策的“快照”。它以自然语言形式阐述了智能体如何分析当前情境、回顾上一步的观察结果、进行自我反思与问题分解，并最终规划出下一步的具体行动。

>Action (行动)：这是智能体基于思考后，决定对环境施加的具体操作，通常以函数调用的形式表示。 

Action比较难理解，虽然知道它指的是调用某种工具或API，但具体怎么调用交给copilot吧-w-。

最核心的代码块应该是这几部分：

1. system prompt：定义智能体的角色和行为准则。
2. tools：智能体可以使用的工具列表。
3. agent config：配置智能体的行为参数，如最大循环次数、调试选项等。
4. llm client：与大语言模型（LLM）交互的接口。

这个得从错误中学习了，跑了一遍代码之后觉得心里有点明白了。大概的流程是：定义好工具，LLM接口, 通过系统提示词来规定智能体的角色和行为准则，传递可用工具的名称，然后让智能体根据用户的输入，利用这些工具来完成任务。示例代码用的是re匹配工具调用的结果，感觉有点outdated，应该用更结构化的方式来处理工具调用和结果的。

话说回来，目前我自己似乎想不到哪里需要AGENT（明明那么火！）。唯一天天在用的就是copilot，github和openai的copilot都非常好用了，其他地方我似乎暂时用不上？唯一可能需要使用的还是RAG吧，但是RAG里面嵌入Agent的必要性我现在还没见到。

## Reflection 反思

教程 https://datawhalechina.github.io/hello-agents/#/./chapter1/%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E5%88%9D%E8%AF%86%E6%99%BA%E8%83%BD%E4%BD%93 提到的智能体分类，例如反射型智能体、基于模型的智能体等，我觉得其实统一翻译成智能体有种误导性，感觉更像是“代理”或者“代理程序”，因为这些智能体并不具备真正的自主性，而是按照预设的规则或模型来运行的。

而当下大家热烈讨论和想学习的Agent，更多是指具备一定自主性，能够通过与环境交互来完成复杂任务的系统。基于大语言模型（LLM）的智能体我觉得才算真正意义上的“智能”，而不仅仅只是代理。