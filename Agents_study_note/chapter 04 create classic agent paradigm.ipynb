{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac9c14b",
   "metadata": {},
   "source": [
    "# Hello Agents è¯¾ç¨‹ï¼šæ™ºèƒ½ä½“ç»å…¸èŒƒå¼æ„å»º ï¼ˆå­¦ä¹ ç¬”è®°ï¼‰\n",
    "\n",
    "æœ¬ç« èŠ‚åŸå†…å®¹æ¥è‡ª [Hello Agents è¯¾ç¨‹](https://datawhalechina.github.io/hello-agents/)ï¼Œç”± DataWhale ç¤¾åŒºç»´æŠ¤ï¼Œæ„Ÿè°¢åŸä½œè€…çš„è´¡çŒ®ã€‚\n",
    "https://datawhalechina.github.io/hello-agents/#/./chapter4/%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E7%BB%8F%E5%85%B8%E8%8C%83%E5%BC%8F%E6%9E%84%E5%BB%BA?id=_411-%e5%ae%89%e8%a3%85%e4%be%9d%e8%b5%96%e5%ba%93"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0bef00",
   "metadata": {},
   "source": [
    "Hello Agentæ•™ç¨‹é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„ä¸‰ç§æ™ºèƒ½ä½“ï¼Œå¹¶ä¸€æ­¥æ­¥ä»é›¶å®ç°å®ƒä»¬ï¼š\n",
    "\n",
    "- ReAct (Reasoning and Acting)ï¼š ä¸€ç§å°†â€œæ€è€ƒâ€å’Œâ€œè¡ŒåŠ¨â€ç´§å¯†ç»“åˆçš„èŒƒå¼ï¼Œè®©æ™ºèƒ½ä½“è¾¹æƒ³è¾¹åšï¼ŒåŠ¨æ€è°ƒæ•´ã€‚\n",
    "\n",
    "- Plan-and-Solveï¼š ä¸€ç§â€œä¸‰æ€è€Œåè¡Œâ€çš„èŒƒå¼ï¼Œæ™ºèƒ½ä½“é¦–å…ˆç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„è¡ŒåŠ¨è®¡åˆ’ï¼Œç„¶åä¸¥æ ¼æ‰§è¡Œã€‚\n",
    "\n",
    "- Reflectionï¼š ä¸€ç§èµ‹äºˆæ™ºèƒ½ä½“â€œåæ€â€èƒ½åŠ›çš„èŒƒå¼ï¼Œé€šè¿‡è‡ªæˆ‘æ‰¹åˆ¤å’Œä¿®æ­£æ¥ä¼˜åŒ–ç»“æœã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da55431",
   "metadata": {},
   "source": [
    "## ReAct æ™ºèƒ½ä½“\n",
    "\n",
    "ReAct æ™ºèƒ½ä½“ç»“åˆäº†â€œæ€è€ƒâ€ï¼ˆReasoningï¼‰å’Œâ€œè¡ŒåŠ¨â€ï¼ˆActingï¼‰ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨æ‰§è¡Œä»»åŠ¡çš„è¿‡ç¨‹ä¸­åŠ¨æ€åœ°è°ƒæ•´ç­–ç•¥ã€‚ä»¥ä¸‹æ˜¯ ReAct æ™ºèƒ½ä½“çš„æ ¸å¿ƒç»„ä»¶å’Œå®ç°æ­¥éª¤ï¼š\n",
    "\n",
    "1. **ç¯å¢ƒè®¾ç½®**ï¼šå®šä¹‰æ™ºèƒ½ä½“æ‰€å¤„çš„ç¯å¢ƒï¼ŒåŒ…æ‹¬å¯ç”¨çš„å·¥å…·å’Œèµ„æºã€‚\n",
    "2. **æ€è€ƒæ¨¡å—**ï¼šå®ç°ä¸€ä¸ªæ€è€ƒæ¨¡å—ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ ¹æ®å½“å‰çŠ¶æ€å’Œç›®æ ‡è¿›è¡Œæ¨ç†ï¼Œç”Ÿæˆä¸‹ä¸€æ­¥çš„è¡ŒåŠ¨è®¡åˆ’ã€‚\n",
    "3. **è¡ŒåŠ¨æ¨¡å—**ï¼šå®ç°ä¸€ä¸ªè¡ŒåŠ¨æ¨¡å—ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ‰§è¡Œæ€è€ƒæ¨¡å—ç”Ÿæˆçš„è®¡åˆ’ï¼Œå¹¶æ ¹æ®æ‰§è¡Œç»“æœè¿›è¡Œåé¦ˆã€‚\n",
    "   \n",
    "### åˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e010633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08978683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: sk-d7GDhmo...\n",
      "OpenAI Base URL: https://xiaoai.plus/v1\n",
      "OpenAI Model: gpt-5-nano\n"
     ]
    }
   ],
   "source": [
    "# Set API key and base URL globally\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\") # Use correct env var name from your .env or manually set it\n",
    "print(\"OpenAI API Key:\", api_key[:10] + \"...\" if api_key else \"Not found\")  # Only show first 10 chars for security\n",
    "\n",
    "base_url = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")  # Use correct env var name from your .env\n",
    "print(\"OpenAI Base URL:\", base_url)\n",
    "\n",
    "model = os.getenv(\"OPENAI_MODEL\", \"gpt-5-nano\")  # Use correct env var name from your .env\n",
    "print(\"OpenAI Model:\", model)  # Print the model being used\n",
    "\n",
    "# Initialize OpenAI client with API key and base URL\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "242f6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "class HelloAgentsLLM:\n",
    "    def __init__(self, model_name=model):\n",
    "        self.model_name = model_name\n",
    "        apiKey = os.getenv(\"OPENAI_API_KEY\")\n",
    "        baseUrl = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n",
    "        timeout = 60\n",
    "#gpt-5-nano has no temperature parameter?\n",
    "    def think(self, messages: List[Dict[str, str]], temperature: float = 0) -> str:\n",
    "        print(\"Thinking with model:\", self.model_name)\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        print(\"Response received:\", response.choices[0].message.content)\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def generate_response(self, prompt):\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efe9149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- è°ƒç”¨LLM ---\n",
      "Thinking with model: gpt-5-nano\n",
      "Response received: ä¸‹é¢ç»™å‡ºä¸€ä¸ªç®€å•çš„ã€åŸåœ°çš„å¿«é€Ÿæ’åºå®ç°ï¼Œä½¿ç”¨ Lomuto åˆ†åŒºæ–¹æ¡ˆã€‚æ—¶é—´å¤æ‚åº¦å¹³å‡ O(n log n)ï¼Œæœ€å O(n^2)ï¼Œç©ºé—´å¤æ‚åº¦ä¸º O(log n) çš„é€’å½’æ ˆã€‚\n",
      "\n",
      "ä»£ç å¦‚ä¸‹ï¼ˆPythonï¼‰ï¼š\n",
      "\n",
      "def partition(arr, low, high):\n",
      "    # ä»¥ high ä½ç½®çš„å…ƒç´ ä½œä¸º pivot\n",
      "    pivot = arr[high]\n",
      "    i = low\n",
      "    for j in range(low, high):\n",
      "        if arr[j] <= pivot:\n",
      "            arr[i], arr[j] = arr[j], arr[i]\n",
      "            i += 1\n",
      "    arr[i], arr[high] = arr[high], arr[i]\n",
      "    return i\n",
      "\n",
      "def quicksort(arr, low=0, high=None):\n",
      "    if high is None:\n",
      "        high = len(arr) - 1\n",
      "    if low < high:\n",
      "        p = partition(arr, low, high)\n",
      "        quicksort(arr, low, p - 1)\n",
      "        quicksort(arr, p + 1, high)\n",
      "\n",
      "ä½¿ç”¨ç¤ºä¾‹ï¼š\n",
      "\n",
      "lst = [3, 1, 4, 1, 5, 9, 2, 6, 5]\n",
      "quicksort(lst)\n",
      "print(lst)  # è¾“å‡ºå·²æ’åºçš„åˆ—è¡¨\n",
      "\n",
      "å¦‚æœä½ æƒ³è¦ä¸€ä¸ªéåŸåœ°çš„ç‰ˆæœ¬ï¼ˆè¿”å›æ–°æ’å¥½åºçš„åˆ—è¡¨ï¼‰ï¼Œä¹Ÿå¯ä»¥æä¾›ä¸€ä¸ªåŸºäºé€’å½’åˆ’åˆ†çš„å®ç°ã€‚éœ€è¦çš„è¯æˆ‘ç»™ä½ å†™ä¸€ä¸ªã€‚\n",
      "\n",
      "\n",
      "--- å®Œæ•´æ¨¡å‹å“åº” ---\n",
      "ä¸‹é¢ç»™å‡ºä¸€ä¸ªç®€å•çš„ã€åŸåœ°çš„å¿«é€Ÿæ’åºå®ç°ï¼Œä½¿ç”¨ Lomuto åˆ†åŒºæ–¹æ¡ˆã€‚æ—¶é—´å¤æ‚åº¦å¹³å‡ O(n log n)ï¼Œæœ€å O(n^2)ï¼Œç©ºé—´å¤æ‚åº¦ä¸º O(log n) çš„é€’å½’æ ˆã€‚\n",
      "\n",
      "ä»£ç å¦‚ä¸‹ï¼ˆPythonï¼‰ï¼š\n",
      "\n",
      "def partition(arr, low, high):\n",
      "    # ä»¥ high ä½ç½®çš„å…ƒç´ ä½œä¸º pivot\n",
      "    pivot = arr[high]\n",
      "    i = low\n",
      "    for j in range(low, high):\n",
      "        if arr[j] <= pivot:\n",
      "            arr[i], arr[j] = arr[j], arr[i]\n",
      "            i += 1\n",
      "    arr[i], arr[high] = arr[high], arr[i]\n",
      "    return i\n",
      "\n",
      "def quicksort(arr, low=0, high=None):\n",
      "    if high is None:\n",
      "        high = len(arr) - 1\n",
      "    if low < high:\n",
      "        p = partition(arr, low, high)\n",
      "        quicksort(arr, low, p - 1)\n",
      "        quicksort(arr, p + 1, high)\n",
      "\n",
      "ä½¿ç”¨ç¤ºä¾‹ï¼š\n",
      "\n",
      "lst = [3, 1, 4, 1, 5, 9, 2, 6, 5]\n",
      "quicksort(lst)\n",
      "print(lst)  # è¾“å‡ºå·²æ’åºçš„åˆ—è¡¨\n",
      "\n",
      "å¦‚æœä½ æƒ³è¦ä¸€ä¸ªéåŸåœ°çš„ç‰ˆæœ¬ï¼ˆè¿”å›æ–°æ’å¥½åºçš„åˆ—è¡¨ï¼‰ï¼Œä¹Ÿå¯ä»¥æä¾›ä¸€ä¸ªåŸºäºé€’å½’åˆ’åˆ†çš„å®ç°ã€‚éœ€è¦çš„è¯æˆ‘ç»™ä½ å†™ä¸€ä¸ªã€‚\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        llmClient = HelloAgentsLLM()\n",
    "        \n",
    "        exampleMessages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that writes Python code.\"},\n",
    "            {\"role\": \"user\", \"content\": \"å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•\"}\n",
    "        ]\n",
    "        \n",
    "        print(\"--- è°ƒç”¨LLM ---\")\n",
    "        responseText = llmClient.think(exampleMessages)\n",
    "        if responseText:\n",
    "            print(\"\\n\\n--- å®Œæ•´æ¨¡å‹å“åº” ---\")\n",
    "            print(responseText)\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb8ac5",
   "metadata": {},
   "source": [
    "### å·¥å…·å®šä¹‰å’Œå®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e7a3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in d:\\python313\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in d:\\python313\\lib\\site-packages (from google-search-results) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\python313\\lib\\site-packages (from requests->google-search-results) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python313\\lib\\site-packages (from requests->google-search-results) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python313\\lib\\site-packages (from requests->google-search-results) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python313\\lib\\site-packages (from requests->google-search-results) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cf8c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import SerpApiClient\n",
    "\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    ä¸€ä¸ªåŸºäºSerpApiçš„å®æˆ˜ç½‘é¡µæœç´¢å¼•æ“å·¥å…·ã€‚\n",
    "    å®ƒä¼šæ™ºèƒ½åœ°è§£ææœç´¢ç»“æœï¼Œä¼˜å…ˆè¿”å›ç›´æ¥ç­”æ¡ˆæˆ–çŸ¥è¯†å›¾è°±ä¿¡æ¯ã€‚\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” æ­£åœ¨æ‰§è¡Œ [SerpApi] ç½‘é¡µæœç´¢: {query}\")\n",
    "    try:\n",
    "        api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "        if not api_key:\n",
    "            return \"é”™è¯¯:SERPAPI_API_KEY æœªåœ¨ .env æ–‡ä»¶ä¸­é…ç½®ã€‚\"\n",
    "\n",
    "        params = {\n",
    "            \"engine\": \"google\",\n",
    "            \"q\": query,\n",
    "            \"api_key\": api_key,\n",
    "            \"gl\": \"cn\",  # å›½å®¶ä»£ç \n",
    "            \"hl\": \"zh-cn\", # è¯­è¨€ä»£ç \n",
    "        }\n",
    "        \n",
    "        client = SerpApiClient(params)\n",
    "        results = client.get_dict()\n",
    "        \n",
    "        # æ™ºèƒ½è§£æ:ä¼˜å…ˆå¯»æ‰¾æœ€ç›´æ¥çš„ç­”æ¡ˆ\n",
    "        if \"answer_box_list\" in results:\n",
    "            return \"\\n\".join(results[\"answer_box_list\"])\n",
    "        if \"answer_box\" in results and \"answer\" in results[\"answer_box\"]:\n",
    "            return results[\"answer_box\"][\"answer\"]\n",
    "        if \"knowledge_graph\" in results and \"description\" in results[\"knowledge_graph\"]:\n",
    "            return results[\"knowledge_graph\"][\"description\"]\n",
    "        if \"organic_results\" in results and results[\"organic_results\"]:\n",
    "            # å¦‚æœæ²¡æœ‰ç›´æ¥ç­”æ¡ˆï¼Œåˆ™è¿”å›å‰ä¸‰ä¸ªæœ‰æœºç»“æœçš„æ‘˜è¦\n",
    "            snippets = [\n",
    "                f\"[{i+1}] {res.get('title', '')}\\n{res.get('snippet', '')}\"\n",
    "                for i, res in enumerate(results[\"organic_results\"][:3])\n",
    "            ]\n",
    "            return \"\\n\\n\".join(snippets)\n",
    "        \n",
    "        return f\"å¯¹ä¸èµ·ï¼Œæ²¡æœ‰æ‰¾åˆ°å…³äº '{query}' çš„ä¿¡æ¯ã€‚\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ddc662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "class ToolExecutor:\n",
    "    \"\"\"\n",
    "    ä¸€ä¸ªå·¥å…·æ‰§è¡Œå™¨ï¼Œè´Ÿè´£ç®¡ç†å’Œæ‰§è¡Œå·¥å…·ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.tools: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    def registerTool(self, name: str, description: str, func: callable):\n",
    "        \"\"\"\n",
    "        å‘å·¥å…·ç®±ä¸­æ³¨å†Œä¸€ä¸ªæ–°å·¥å…·ã€‚\n",
    "        \"\"\"\n",
    "        if name in self.tools:\n",
    "            print(f\"è­¦å‘Š:å·¥å…· '{name}' å·²å­˜åœ¨ï¼Œå°†è¢«è¦†ç›–ã€‚\")\n",
    "        self.tools[name] = {\"description\": description, \"func\": func}\n",
    "        print(f\"å·¥å…· '{name}' å·²æ³¨å†Œã€‚\")\n",
    "\n",
    "    def getTool(self, name: str) -> callable:\n",
    "        \"\"\"\n",
    "        æ ¹æ®åç§°è·å–ä¸€ä¸ªå·¥å…·çš„æ‰§è¡Œå‡½æ•°ã€‚\n",
    "        \"\"\"\n",
    "        return self.tools.get(name, {}).get(\"func\")\n",
    "\n",
    "    def getAvailableTools(self) -> str:\n",
    "        \"\"\"\n",
    "        è·å–æ‰€æœ‰å¯ç”¨å·¥å…·çš„æ ¼å¼åŒ–æè¿°å­—ç¬¦ä¸²ã€‚\n",
    "        \"\"\"\n",
    "        return \"\\n\".join([\n",
    "            f\"- {name}: {info['description']}\" \n",
    "            for name, info in self.tools.items()\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc6b89d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·¥å…· 'Search' å·²æ³¨å†Œã€‚\n",
      "\n",
      "--- å¯ç”¨çš„å·¥å…· ---\n",
      "- Search: ä¸€ä¸ªç½‘é¡µæœç´¢å¼•æ“ã€‚å½“ä½ éœ€è¦å›ç­”å…³äºæ—¶äº‹ã€äº‹å®ä»¥åŠåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚\n",
      "\n",
      "--- æ‰§è¡Œ Action: Search['è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ'] ---\n",
      "ğŸ” æ­£åœ¨æ‰§è¡Œ [SerpApi] ç½‘é¡µæœç´¢: è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ\n",
      "--- è§‚å¯Ÿ (Observation) ---\n",
      "[1] æ¯”è¾ƒGeForce ç³»åˆ—æœ€æ–°ä¸€ä»£æ˜¾å¡å’Œå‰ä»£æ˜¾å¡\n",
      "æ¯”è¾ƒæœ€æ–°ä¸€ä»£RTX 30 ç³»åˆ—æ˜¾å¡å’Œå‰ä»£çš„RTX 20 ç³»åˆ—ã€GTX 10 å’Œ900 ç³»åˆ—æ˜¾å¡ã€‚æŸ¥çœ‹è§„æ ¼ã€åŠŸèƒ½ã€æŠ€æœ¯æ”¯æŒç­‰å†…å®¹ã€‚\n",
      "\n",
      "[2] GeForce RTX 50 ç³»åˆ—æ˜¾å¡\n",
      "GeForce RTXâ„¢ 50 ç³»åˆ—GPU æ­è½½NVIDIA Blackwell æ¶æ„ï¼Œä¸ºæ¸¸æˆç©å®¶å’Œåˆ›ä½œè€…å¸¦æ¥å…¨æ–°ç©æ³•ã€‚RTX 50 ç³»åˆ—å…·å¤‡å¼ºå¤§çš„AI ç®—åŠ›ï¼Œå¸¦æ¥å‡çº§ä½“éªŒå’Œæ›´é€¼çœŸçš„ç”»é¢ã€‚\n",
      "\n",
      "[3] ä¸€æ–‡å½»åº•è¯»æ‡‚ï¼šè‹±ä¼Ÿè¾¾GPUåˆ†ç±»ã€æ¶æ„æ¼”è¿›å’Œå‚æ•°è§£æ\n",
      "Quadroç³»åˆ—æ˜¯è‹±ä¼Ÿè¾¾ä¸“ä¸šçº§GPUäº§å“çº¿ï¼Œé’ˆå¯¹å•†ä¸šå’Œä¸“ä¸šåº”ç”¨é¢†åŸŸè¿›è¡Œäº†ä¼˜åŒ–ã€‚å¸¸è§çš„äº§å“å‹å·å¦‚NVIDIA RTX A6000ã€A5000ç­‰ã€‚ Quadro GPUå…·å¤‡å¼ºå¤§çš„è®¡ç®—èƒ½åŠ›ã€å¤§ ...\n"
     ]
    }
   ],
   "source": [
    "# --- å·¥å…·åˆå§‹åŒ–ä¸ä½¿ç”¨ç¤ºä¾‹ ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. åˆå§‹åŒ–å·¥å…·æ‰§è¡Œå™¨\n",
    "    toolExecutor = ToolExecutor()\n",
    "\n",
    "    # 2. æ³¨å†Œæˆ‘ä»¬çš„å®æˆ˜æœç´¢å·¥å…·\n",
    "    search_description = \"ä¸€ä¸ªç½‘é¡µæœç´¢å¼•æ“ã€‚å½“ä½ éœ€è¦å›ç­”å…³äºæ—¶äº‹ã€äº‹å®ä»¥åŠåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚\"\n",
    "    toolExecutor.registerTool(\"Search\", search_description, search)\n",
    "    \n",
    "    # 3. æ‰“å°å¯ç”¨çš„å·¥å…·\n",
    "    print(\"\\n--- å¯ç”¨çš„å·¥å…· ---\")\n",
    "    print(toolExecutor.getAvailableTools())\n",
    "\n",
    "    # 4. æ™ºèƒ½ä½“çš„Actionè°ƒç”¨ï¼Œè¿™æ¬¡æˆ‘ä»¬é—®ä¸€ä¸ªå®æ—¶æ€§çš„é—®é¢˜\n",
    "    print(\"\\n--- æ‰§è¡Œ Action: Search['è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ'] ---\")\n",
    "    tool_name = \"Search\"\n",
    "    tool_input = \"è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ\"\n",
    "\n",
    "    tool_function = toolExecutor.getTool(tool_name)\n",
    "    if tool_function:\n",
    "        observation = tool_function(tool_input)\n",
    "        print(\"--- è§‚å¯Ÿ (Observation) ---\")\n",
    "        print(observation)\n",
    "    else:\n",
    "        print(f\"é”™è¯¯:æœªæ‰¾åˆ°åä¸º '{tool_name}' çš„å·¥å…·ã€‚\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f658afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct æç¤ºè¯æ¨¡æ¿\n",
    "REACT_PROMPT_TEMPLATE = \"\"\"\n",
    "è¯·æ³¨æ„ï¼Œä½ æ˜¯ä¸€ä¸ªæœ‰èƒ½åŠ›è°ƒç”¨å¤–éƒ¨å·¥å…·çš„æ™ºèƒ½åŠ©æ‰‹ã€‚\n",
    "\n",
    "å¯ç”¨å·¥å…·å¦‚ä¸‹:\n",
    "{tools}\n",
    "\n",
    "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿›è¡Œå›åº”:\n",
    "\n",
    "Thought: ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œç”¨äºåˆ†æé—®é¢˜ã€æ‹†è§£ä»»åŠ¡å’Œè§„åˆ’ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚\n",
    "Action: ä½ å†³å®šé‡‡å–çš„è¡ŒåŠ¨ï¼Œå¿…é¡»æ˜¯ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€:\n",
    "- `{{tool_name}}[{{tool_input}}]`:è°ƒç”¨ä¸€ä¸ªå¯ç”¨å·¥å…·ã€‚\n",
    "- `Finish[æœ€ç»ˆç­”æ¡ˆ]`:å½“ä½ è®¤ä¸ºå·²ç»è·å¾—æœ€ç»ˆç­”æ¡ˆæ—¶ã€‚\n",
    "- å½“ä½ æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œèƒ½å¤Ÿå›ç­”ç”¨æˆ·çš„æœ€ç»ˆé—®é¢˜æ—¶ï¼Œä½ å¿…é¡»åœ¨Action:å­—æ®µåä½¿ç”¨ finish(answer=\"...\") æ¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆã€‚\n",
    "\n",
    "ç°åœ¨ï¼Œè¯·å¼€å§‹è§£å†³ä»¥ä¸‹é—®é¢˜:\n",
    "Question: {question}\n",
    "History: {history}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f99d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActAgent:\n",
    "    def __init__(self, llm_client: HelloAgentsLLM, tool_executor: ToolExecutor, max_steps: int = 5):\n",
    "        self.llm_client = llm_client\n",
    "        self.tool_executor = tool_executor\n",
    "        self.max_steps = max_steps\n",
    "        self.history = []\n",
    "\n",
    "    def run(self, question: str):\n",
    "        \"\"\"\n",
    "        è¿è¡ŒReActæ™ºèƒ½ä½“æ¥å›ç­”ä¸€ä¸ªé—®é¢˜ã€‚\n",
    "        \"\"\"\n",
    "        self.history = [] # æ¯æ¬¡è¿è¡Œæ—¶é‡ç½®å†å²è®°å½•\n",
    "        current_step = 0\n",
    "\n",
    "        while current_step < self.max_steps:\n",
    "            current_step += 1\n",
    "            print(f\"--- ç¬¬ {current_step} æ­¥ ---\")\n",
    "\n",
    "            # 1. æ ¼å¼åŒ–æç¤ºè¯\n",
    "            tools_desc = self.tool_executor.getAvailableTools()\n",
    "            history_str = \"\\n\".join(self.history)\n",
    "            prompt = REACT_PROMPT_TEMPLATE.format(\n",
    "                tools=tools_desc,\n",
    "                question=question,\n",
    "                history=history_str\n",
    "            )\n",
    "\n",
    "            # 2. è°ƒç”¨LLMè¿›è¡Œæ€è€ƒ\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            response_text = self.llm_client.think(messages=messages)\n",
    "            \n",
    "            if not response_text:\n",
    "                print(\"é”™è¯¯:LLMæœªèƒ½è¿”å›æœ‰æ•ˆå“åº”ã€‚\")\n",
    "                break\n",
    "            # (è¿™æ®µé€»è¾‘åœ¨ run æ–¹æ³•çš„ while å¾ªç¯å†…)\n",
    "            # 3. è§£æLLMçš„è¾“å‡º\n",
    "            thought, action = self._parse_output(response_text)\n",
    "            \n",
    "            if thought:\n",
    "                print(f\"æ€è€ƒ: {thought}\")\n",
    "\n",
    "            if not action:\n",
    "                print(\"è­¦å‘Š:æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„Actionï¼Œæµç¨‹ç»ˆæ­¢ã€‚\")\n",
    "                break\n",
    "\n",
    "            # 4. æ‰§è¡ŒAction\n",
    "            if action.startswith(\"Finish\"):\n",
    "                # å¦‚æœæ˜¯FinishæŒ‡ä»¤ï¼Œæå–æœ€ç»ˆç­”æ¡ˆå¹¶ç»“æŸ\n",
    "                final_answer = re.match(r\"Finish\\[(.*)\\]\", action).group(1)\n",
    "                print(f\"ğŸ‰ æœ€ç»ˆç­”æ¡ˆ: {final_answer}\")\n",
    "                return final_answer\n",
    "            \n",
    "            tool_name, tool_input = self._parse_action(action)\n",
    "            if not tool_name or not tool_input:\n",
    "                # ... å¤„ç†æ— æ•ˆActionæ ¼å¼ ...\n",
    "                continue\n",
    "\n",
    "            print(f\"ğŸ¬ è¡ŒåŠ¨: {tool_name}[{tool_input}]\")\n",
    "            \n",
    "            tool_function = self.tool_executor.getTool(tool_name)\n",
    "            if not tool_function:\n",
    "                observation = f\"é”™è¯¯:æœªæ‰¾åˆ°åä¸º '{tool_name}' çš„å·¥å…·ã€‚\"\n",
    "            else:\n",
    "                observation = tool_function(tool_input) # è°ƒç”¨çœŸå®å·¥å…·\n",
    "\n",
    "            ## (è¿™æ®µé€»è¾‘ç´§éšå·¥å…·è°ƒç”¨ä¹‹åï¼Œåœ¨ while å¾ªç¯çš„æœ«å°¾)\n",
    "            print(f\"ğŸ‘€ è§‚å¯Ÿ: {observation}\")\n",
    "            \n",
    "            # å°†æœ¬è½®çš„Actionå’ŒObservationæ·»åŠ åˆ°å†å²è®°å½•ä¸­\n",
    "            self.history.append(f\"Action: {action}\")\n",
    "            self.history.append(f\"Observation: {observation}\")\n",
    "\n",
    "        # å¾ªç¯ç»“æŸ\n",
    "        print(\"å·²è¾¾åˆ°æœ€å¤§æ­¥æ•°ï¼Œæµç¨‹ç»ˆæ­¢ã€‚\")\n",
    "        return None\n",
    "\n",
    "# (è¿™äº›æ–¹æ³•æ˜¯ ReActAgent ç±»çš„ä¸€éƒ¨åˆ†)\n",
    "    def _parse_output(self, text: str):\n",
    "        \"\"\"è§£æLLMçš„è¾“å‡ºï¼Œæå–Thoughtå’ŒActionã€‚\"\"\"\n",
    "        thought_match = re.search(r\"Thought: (.*)\", text)\n",
    "        action_match = re.search(r\"Action: (.*)\", text)\n",
    "        thought = thought_match.group(1).strip() if thought_match else None\n",
    "        action = action_match.group(1).strip() if action_match else None\n",
    "        return thought, action\n",
    "\n",
    "    def _parse_action(self, action_text: str):\n",
    "        \"\"\"è§£æActionå­—ç¬¦ä¸²ï¼Œæå–å·¥å…·åç§°å’Œè¾“å…¥ã€‚\"\"\"\n",
    "        match = re.match(r\"(\\w+)\\[(.*)\\]\", action_text)\n",
    "        if match:\n",
    "            return match.group(1), match.group(2)\n",
    "        return None, None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed3926fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·¥å…· 'Search' å·²æ³¨å†Œã€‚\n",
      "\n",
      "===== æµ‹è¯• ReActAgent =====\n",
      "--- ç¬¬ 1 æ­¥ ---\n",
      "Thinking with model: gpt-5-nano\n",
      "Response received: Thought: æˆ‘éœ€è¦é€šè¿‡ç½‘ç»œæœ€æ–°ä¿¡æ¯æ¥ç¡®å®šNVIDIAå½“å‰æœ€æ–°çš„GPUå‹å·ï¼Œå› ä¸ºè¿™æ˜¯æ—¶æ•ˆæ€§å¾ˆå¼ºçš„äº‹å®æ€§é—®é¢˜ï¼Œå¯èƒ½åœ¨çŸ¥è¯†åº“ä¹‹å¤–ã€‚å°†è¿›è¡Œç½‘é¡µæœç´¢ä»¥è·å–å®˜æ–¹å…¬å‘Šæˆ–æƒå¨åª’ä½“çš„æœ€æ–°æŠ¥é“ã€‚\n",
      "\n",
      "Action: Search[NVIDIA latest GPU model 2024 2025 RTX 50 series 5090]\n",
      "æ€è€ƒ: æˆ‘éœ€è¦é€šè¿‡ç½‘ç»œæœ€æ–°ä¿¡æ¯æ¥ç¡®å®šNVIDIAå½“å‰æœ€æ–°çš„GPUå‹å·ï¼Œå› ä¸ºè¿™æ˜¯æ—¶æ•ˆæ€§å¾ˆå¼ºçš„äº‹å®æ€§é—®é¢˜ï¼Œå¯èƒ½åœ¨çŸ¥è¯†åº“ä¹‹å¤–ã€‚å°†è¿›è¡Œç½‘é¡µæœç´¢ä»¥è·å–å®˜æ–¹å…¬å‘Šæˆ–æƒå¨åª’ä½“çš„æœ€æ–°æŠ¥é“ã€‚\n",
      "ğŸ¬ è¡ŒåŠ¨: Search[NVIDIA latest GPU model 2024 2025 RTX 50 series 5090]\n",
      "ğŸ” æ­£åœ¨æ‰§è¡Œ [SerpApi] ç½‘é¡µæœç´¢: NVIDIA latest GPU model 2024 2025 RTX 50 series 5090\n",
      "ğŸ‘€ è§‚å¯Ÿ: [1] GeForce RTX 5090 Graphics Cards\n",
      "The GeForce RTX 5090 is powered by the NVIDIA Blackwell architecture and equipped with 32 GB of super-fast GDDR7 memory, so you can do it all. Starting at $1999.\n",
      "\n",
      "[2] GeForce RTX 5090 D v2 æ˜¾å¡| NVIDIA\n",
      "NVIDIAÂ® GeForce RTXâ„¢ 5090 D v2 å¯ä¸ºæ¸¸æˆç©å®¶å’Œåˆ›ä½œè€…å¸¦æ¥å…¨æ–°ç©æ³•ã€‚å®ƒå…·æœ‰å¼ºå¤§AI ç®—åŠ›ï¼Œèƒ½å¤Ÿå¤„ç†å‰æ²¿çš„æ¨¡å‹ï¼Œåº”å¯¹æŒ‘æˆ˜æ€§çš„åˆ›æ„å·¥ä½œæµã€‚åœ¨æ¸¸æˆä½“éªŒä¸­ï¼Œæ”¯æŒå…¨æ™¯å…‰çº¿è¿½è¸ª ...\n",
      "\n",
      "[3] GeForce RTX 50 Series Graphics Cards\n",
      "Equipped with a massive level of AI horsepower, the RTX 50 Series enables new experiences and next-level graphics fidelity.\n",
      "--- ç¬¬ 2 æ­¥ ---\n",
      "Thinking with model: gpt-5-nano\n",
      "Response received: Thought: å°†é€šè¿‡æœç´¢æ ¸å®æœ€æ–°çš„ NVIDIA GPU å‹å·å¹¶æ±‡æ€»å…³é”®è§„æ ¼ï¼Œä»¥ä¾¿ç»™å‡ºæ˜ç¡®çš„ç»“è®ºã€‚\n",
      "\n",
      "Action: Search[NVIDIA latest GPU model 2024 2025 RTX 50 series 5090]\n",
      "\n",
      "finish(answer=\"æ ¹æ®å…¬å¼€ä¿¡æ¯ï¼ŒNVIDIA å½“å‰è¢«å¹¿æ³›æŠ¥é“çš„æœ€æ–° GPU å‹å·æ˜¯ GeForce RTX 5090ï¼ˆåŸºäº Blackwell æ¶æ„ï¼Œé…å¤‡ 32 GB GDDR7 æ˜¾å­˜ï¼Œèµ·å”®ä»·çº¦ 1999 ç¾å…ƒï¼‰ã€‚å¦å¤–è¿˜æœ‰ RTX 5090 D v2 ç‰ˆæœ¬ï¼Œé¢å‘æ¸¸æˆç©å®¶å’Œåˆ›ä½œè€…ï¼Œæä¾›æ›´å¼ºçš„ AI è®¡ç®—èƒ½åŠ›ã€‚RTX 50 Series æ„æˆäº†è¿™ä»£çš„æ•´æ¡æ–°ç³»åˆ—ï¼Œå¼ºè°ƒæ›´é«˜çš„ AI æ€§èƒ½å’Œå›¾å½¢ä¿çœŸåº¦ã€‚\")\n",
      "æ€è€ƒ: å°†é€šè¿‡æœç´¢æ ¸å®æœ€æ–°çš„ NVIDIA GPU å‹å·å¹¶æ±‡æ€»å…³é”®è§„æ ¼ï¼Œä»¥ä¾¿ç»™å‡ºæ˜ç¡®çš„ç»“è®ºã€‚\n",
      "ğŸ¬ è¡ŒåŠ¨: Search[NVIDIA latest GPU model 2024 2025 RTX 50 series 5090]\n",
      "ğŸ” æ­£åœ¨æ‰§è¡Œ [SerpApi] ç½‘é¡µæœç´¢: NVIDIA latest GPU model 2024 2025 RTX 50 series 5090\n",
      "ğŸ‘€ è§‚å¯Ÿ: [1] GeForce RTX 5090 Graphics Cards\n",
      "The GeForce RTX 5090 is powered by the NVIDIA Blackwell architecture and equipped with 32 GB of super-fast GDDR7 memory, so you can do it all. Starting at $1999.\n",
      "\n",
      "[2] GeForce RTX 5090 D v2 æ˜¾å¡| NVIDIA\n",
      "NVIDIAÂ® GeForce RTXâ„¢ 5090 D v2 å¯ä¸ºæ¸¸æˆç©å®¶å’Œåˆ›ä½œè€…å¸¦æ¥å…¨æ–°ç©æ³•ã€‚å®ƒå…·æœ‰å¼ºå¤§AI ç®—åŠ›ï¼Œèƒ½å¤Ÿå¤„ç†å‰æ²¿çš„æ¨¡å‹ï¼Œåº”å¯¹æŒ‘æˆ˜æ€§çš„åˆ›æ„å·¥ä½œæµã€‚åœ¨æ¸¸æˆä½“éªŒä¸­ï¼Œæ”¯æŒå…¨æ™¯å…‰çº¿è¿½è¸ª ...\n",
      "\n",
      "[3] GeForce RTX 50 Series Graphics Cards\n",
      "Equipped with a massive level of AI horsepower, the RTX 50 Series enables new experiences and next-level graphics fidelity.\n",
      "--- ç¬¬ 3 æ­¥ ---\n",
      "Thinking with model: gpt-5-nano\n",
      "Response received: Thought: å·²é€šè¿‡æ£€ç´¢ç¡®è®¤ NVIDIA ç›®å‰çš„æœ€æ–° GPU æ˜¯ GeForce RTX 5090ï¼Œå±äº RTX 50 ç³»åˆ—ï¼›å­˜åœ¨å˜ä½“ RTX 5090 D v2ã€‚å¯æä¾›çš„æ ¸å¿ƒä¿¡æ¯åŒ…æ‹¬å†…å­˜è§„æ ¼å’Œèµ·å§‹ä»·æ ¼ã€‚\n",
      "\n",
      "Action: Finish[answer=\"æœ€æ–°çš„ NVIDIA GPU å‹å·æ˜¯ GeForce RTX 5090ï¼ˆRTX 50 ç³»åˆ—ï¼‰ã€‚å®ƒåŸºäº Blackwell æ¶æ„ï¼Œé…ç½®ä¸º 32 GB GDDR7 å†…å­˜ï¼Œèµ·ä»·çº¦ 1999 ç¾å…ƒã€‚å¦æœ‰ RTX 5090 D v2 å˜ä½“ï¼Œé¢å‘æ¸¸æˆç©å®¶å’Œåˆ›ä½œè€…ï¼Œæä¾›å¢å¼ºçš„ AI è®¡ç®—èƒ½åŠ›å’Œå…¨æ™¯å…‰çº¿è¿½è¸ªç­‰ç‰¹æ€§ã€‚\"]\n",
      "æ€è€ƒ: å·²é€šè¿‡æ£€ç´¢ç¡®è®¤ NVIDIA ç›®å‰çš„æœ€æ–° GPU æ˜¯ GeForce RTX 5090ï¼Œå±äº RTX 50 ç³»åˆ—ï¼›å­˜åœ¨å˜ä½“ RTX 5090 D v2ã€‚å¯æä¾›çš„æ ¸å¿ƒä¿¡æ¯åŒ…æ‹¬å†…å­˜è§„æ ¼å’Œèµ·å§‹ä»·æ ¼ã€‚\n",
      "ğŸ‰ æœ€ç»ˆç­”æ¡ˆ: answer=\"æœ€æ–°çš„ NVIDIA GPU å‹å·æ˜¯ GeForce RTX 5090ï¼ˆRTX 50 ç³»åˆ—ï¼‰ã€‚å®ƒåŸºäº Blackwell æ¶æ„ï¼Œé…ç½®ä¸º 32 GB GDDR7 å†…å­˜ï¼Œèµ·ä»·çº¦ 1999 ç¾å…ƒã€‚å¦æœ‰ RTX 5090 D v2 å˜ä½“ï¼Œé¢å‘æ¸¸æˆç©å®¶å’Œåˆ›ä½œè€…ï¼Œæä¾›å¢å¼ºçš„ AI è®¡ç®—èƒ½åŠ›å’Œå…¨æ™¯å…‰çº¿è¿½è¸ªç­‰ç‰¹æ€§ã€‚\"\n",
      "\n",
      "æœ€ç»ˆç­”æ¡ˆ: answer=\"æœ€æ–°çš„ NVIDIA GPU å‹å·æ˜¯ GeForce RTX 5090ï¼ˆRTX 50 ç³»åˆ—ï¼‰ã€‚å®ƒåŸºäº Blackwell æ¶æ„ï¼Œé…ç½®ä¸º 32 GB GDDR7 å†…å­˜ï¼Œèµ·ä»·çº¦ 1999 ç¾å…ƒã€‚å¦æœ‰ RTX 5090 D v2 å˜ä½“ï¼Œé¢å‘æ¸¸æˆç©å®¶å’Œåˆ›ä½œè€…ï¼Œæä¾›å¢å¼ºçš„ AI è®¡ç®—èƒ½åŠ›å’Œå…¨æ™¯å…‰çº¿è¿½è¸ªç­‰ç‰¹æ€§ã€‚\"\n"
     ]
    }
   ],
   "source": [
    "# test ReActAgent\n",
    "import re\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯å’Œå·¥å…·æ‰§è¡Œå™¨\n",
    "    llm_client = HelloAgentsLLM()\n",
    "    tool_executor = ToolExecutor()\n",
    "    search_description = \"ä¸€ä¸ªç½‘é¡µæœç´¢å¼•æ“ã€‚å½“ä½ éœ€è¦å›ç­”å…³äºæ—¶äº‹ã€äº‹å®ä»¥åŠåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚\"\n",
    "    tool_executor.registerTool(\"Search\", search_description, search)\n",
    "\n",
    "    # åˆ›å»º ReActAgent å®ä¾‹\n",
    "    agent = ReActAgent(llm_client, tool_executor, max_steps=3)\n",
    "\n",
    "    # æµ‹è¯•é—®é¢˜\n",
    "    question = \"è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆï¼Ÿ\"\n",
    "    print(\"\\n===== æµ‹è¯• ReActAgent =====\")\n",
    "    answer = agent.run(question)\n",
    "    print(\"\\næœ€ç»ˆç­”æ¡ˆ:\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13322895",
   "metadata": {},
   "source": [
    "## Plan-and-Solve\n",
    "\n",
    "æ„Ÿè§‰ä¸åƒä¸€ä¸ªæ™ºèƒ½ä½“ï¼Œæ›´åƒä¸€ä¸ªä¾èµ–é•¿ä¸Šä¸‹æ–‡è®°å¿†çš„æ™®é€šLLMã€‚è¿™ç§å¾ªç¯æ‰§è¡Œçš„æ–¹å¼ï¼Œå’ŒReActçš„è¾¹æƒ³è¾¹åšæœ‰æœ¬è´¨åŒºåˆ«ã€‚è¿™ç§å¯¹çº¿æ€§çš„ç®€å•ä»»åŠ¡æ”¯æŒè¿˜å¥½ï¼Œç¨å¾®å¤æ‚ä¸€ç‚¹åº”è¯¥æ˜¯ä¸è¡Œçš„ã€‚\n",
    "\n",
    "å¦‚æœæ˜¯å¤æ‚çš„è®¡åˆ’å’Œä»»åŠ¡ï¼Œä¸ªäººè§‰å¾—ç»´æŠ¤å‡ ä¸ªAIå¯ä»¥accessçš„å¤–éƒ¨é¡¹ç›®æ–‡æ¡£æ˜¯æ›´ç¨³å¦¥çš„ã€‚ä¾‹å¦‚æ¸…æ™°çš„éœ€æ±‚æ–‡æ¡£ï¼Œä»»åŠ¡åˆ†è§£æ–‡æ¡£ï¼Œé¡¹ç›®è¿›åº¦æ–‡æ¡£ç­‰ã€‚è®©AIå¯ä»¥éšæ—¶æŸ¥è¯¢å’Œæ›´æ–°è¿™äº›æ–‡æ¡£ï¼Œåº”è¯¥ä¼šæ¯”å•çº¯ä¾èµ–ä¸Šä¸‹æ–‡è®°å¿†æ›´é è°±ã€‚\n",
    "\n",
    "è¿™ä¸ªæ™ºèƒ½ä½“è·³è¿‡äº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3fee6",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "Reflection æœºåˆ¶æ¯”è¾ƒæœ‰æ„æ€ï¼Œæ„Ÿè§‰æ›´å¥½åœ°â€œæ¨¡ä»¿â€äº†äººç±»æ€è€ƒçš„æµç¨‹ã€‚\n",
    "\n",
    "æ ¸å¿ƒå·¥ä½œæµç¨‹å¯ä»¥æ¦‚æ‹¬ä¸ºä¸€ä¸ªç®€æ´çš„ä¸‰æ­¥å¾ªç¯ï¼šæ‰§è¡Œ -> åæ€ -> ä¼˜åŒ–ã€‚\n",
    "\n",
    "- æ‰§è¡Œ (Execution)ï¼šé¦–å…ˆï¼Œæ™ºèƒ½ä½“ä½¿ç”¨æˆ‘ä»¬ç†Ÿæ‚‰çš„æ–¹æ³•ï¼ˆå¦‚ ReAct æˆ– Plan-and-Solveï¼‰å°è¯•å®Œæˆä»»åŠ¡ï¼Œç”Ÿæˆä¸€ä¸ªåˆæ­¥çš„è§£å†³æ–¹æ¡ˆæˆ–è¡ŒåŠ¨è½¨è¿¹ã€‚è¿™å¯ä»¥çœ‹ä½œæ˜¯â€œåˆç¨¿â€ã€‚\n",
    "- åæ€ (Reflection)ï¼šæ¥ç€ï¼Œæ™ºèƒ½ä½“è¿›å…¥åæ€é˜¶æ®µã€‚å®ƒä¼šè°ƒç”¨ä¸€ä¸ªç‹¬ç«‹çš„ã€æˆ–è€…å¸¦æœ‰ç‰¹æ®Šæç¤ºè¯çš„å¤§è¯­è¨€æ¨¡å‹å®ä¾‹ï¼Œæ¥æ‰®æ¼”ä¸€ä¸ªâ€œè¯„å®¡å‘˜â€çš„è§’è‰²ã€‚è¿™ä¸ªâ€œè¯„å®¡å‘˜â€ä¼šå®¡è§†ç¬¬ä¸€æ­¥ç”Ÿæˆçš„â€œåˆç¨¿â€ï¼Œå¹¶ä»å¤šä¸ªç»´åº¦è¿›è¡Œè¯„ä¼°ï¼Œä¾‹å¦‚ï¼š\n",
    "  - äº‹å®æ€§é”™è¯¯ï¼šæ˜¯å¦å­˜åœ¨ä¸å¸¸è¯†æˆ–å·²çŸ¥äº‹å®ç›¸æ‚–çš„å†…å®¹ï¼Ÿ\n",
    "  - é€»è¾‘æ¼æ´ï¼šæ¨ç†è¿‡ç¨‹æ˜¯å¦å­˜åœ¨ä¸è¿è´¯æˆ–çŸ›ç›¾ä¹‹å¤„ï¼Ÿ\n",
    "  - æ•ˆç‡é—®é¢˜ï¼šæ˜¯å¦æœ‰æ›´ç›´æ¥ã€æ›´ç®€æ´çš„è·¯å¾„æ¥å®Œæˆä»»åŠ¡ï¼Ÿ\n",
    "  - é—æ¼ä¿¡æ¯ï¼šæ˜¯å¦å¿½ç•¥äº†é—®é¢˜çš„æŸäº›å…³é”®çº¦æŸæˆ–æ–¹é¢ï¼Ÿ æ ¹æ®è¯„ä¼°ï¼Œå®ƒä¼šç”Ÿæˆä¸€æ®µç»“æ„åŒ–çš„åé¦ˆ (Feedback)ï¼ŒæŒ‡å‡ºå…·ä½“çš„é—®é¢˜æ‰€åœ¨å’Œæ”¹è¿›å»ºè®®ã€‚\n",
    "- ä¼˜åŒ– (Refinement)ï¼šæœ€åï¼Œæ™ºèƒ½ä½“å°†â€œåˆç¨¿â€å’Œâ€œåé¦ˆâ€ä½œä¸ºæ–°çš„ä¸Šä¸‹æ–‡ï¼Œå†æ¬¡è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ï¼Œè¦æ±‚å®ƒæ ¹æ®åé¦ˆå†…å®¹å¯¹åˆç¨¿è¿›è¡Œä¿®æ­£ï¼Œç”Ÿæˆä¸€ä¸ªæ›´å®Œå–„çš„â€œä¿®è®¢ç¨¿â€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc046e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
