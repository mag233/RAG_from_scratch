{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e48a319",
   "metadata": {},
   "source": [
    "# 智能体框架 Framework\n",
    "\n",
    "照例先感谢Datawhale的课程：https://datawhalechina.github.io/hello-agents/#/./chapter6/%E7%AC%AC%E5%85%AD%E7%AB%A0%20%E6%A1%86%E6%9E%B6%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5\n",
    "\n",
    "课程介绍了四种主流的智能体框架：\n",
    "\n",
    "- Autogen\n",
    "\n",
    "- AgentScope\n",
    "\n",
    "- CAMEL\n",
    "\n",
    "- LangGraph\n",
    "\n",
    "每个框架都有自己优缺点，教程里都有，不再复述。重点还是实践。\n",
    "\n",
    "从自己最感兴趣的开始，首先是LangGraph。\n",
    "\n",
    "## LangGraph\n",
    "\n",
    "最重要的概念是graph，图。图由节点（node）和边（edge）组成。节点表示任务或操作，边表示节点之间的关系或数据流。\n",
    "\n",
    "Node我就简单粗暴地理解为函数(Function)，而state是函数的输入输出。到了某个edge（END）时，表示图的执行结束，输出结果。\n",
    "\n",
    "Graph是某种由所有参与方都能看到的共享知识库（shared knowledge base），所有节点和边的信息都存储在图中，供后续节点查询和使用。\n",
    "\n",
    "挺抽象的，和chatGPT学习了几轮之后，一起完成了下面的代码。\n",
    "\n",
    "比较简单的流程：\n",
    "\n",
    "1. 用户输入一个主题(topic)。\n",
    "2. 第一个节点(NODE 1)生成与主题的大纲(Outline)。\n",
    "3. 第二个节点(NODE 2)根据大纲生成详细内容(draft)。\n",
    "4. 第三个节点(NODE 3)对内容进行润色(refine），指定风格。\n",
    "\n",
    "实际测试了几轮下来，英文输出比中文好很多，可能是gpt本身的语言能力+我本身习惯用英文提示词？\n",
    "\n",
    "流程完全没问题，挺有意思的。感觉就是把AI给串在一起了。\n",
    "\n",
    "如果是特别简单的应用，应该不依赖框架，也能直接通过输入-输出-输入这样的流动串起来。但是框架给了建造复杂智能体的可能性，等课程学完了可以好好琢磨下。\n",
    "\n",
    "这个agent的课程比往期课程的强度要大，感觉三天时间好紧张，没办法一一完成测试和学习了，只能挑挑拣拣，按照自己的能力和兴趣来学了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dabd60bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Running the agent graph"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Initial state:**\n",
       "\n",
       "```json\n",
       "{'topic': 'elderly smartphone usage and health'}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Node: make_outline — topic: **elderly smartphone usage and health**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM prompt:**\n",
       "```text\n",
       "You are an assistant that writes short article outlines.\n",
       "Produce a concise outline (3-5 bullet points) for an article about: elderly smartphone usage and health\n",
       "Return the outline as plain text, each bullet on a new line.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM response:**\n",
       "```text\n",
       "- Benefits: how smartphones support seniors through social connection, telehealth, medication reminders, and emergency alerts.\n",
       "\n",
       "- Health risks and mitigations: address eye strain, sleep disruption, and posture issues with accessibility settings, blue-light filters, larger text, and regular breaks.\n",
       "\n",
       "- Practical guidelines for adoption: recommend senior-friendly devices and apps, voice assistants, clear onboarding, and ongoing tech support with caregiver involvement.\n",
       "\n",
       "- Safety, privacy, and support: emphasize data privacy, scam awareness, built-in safety features (fall detection, SOS), and access to local training resources.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Outline (stored to state):**\n",
       "\n",
       "```text\n",
       "- Benefits: how smartphones support seniors through social connection, telehealth, medication reminders, and emergency alerts.\n",
       "\n",
       "- Health risks and mitigations: address eye strain, sleep disruption, and posture issues with accessibility settings, blue-light filters, larger text, and regular breaks.\n",
       "\n",
       "- Practical guidelines for adoption: recommend senior-friendly devices and apps, voice assistants, clear onboarding, and ongoing tech support with caregiver involvement.\n",
       "\n",
       "- Safety, privacy, and support: emphasize data privacy, scam awareness, built-in safety features (fall detection, SOS), and access to local training resources.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Node: write_draft — using outline above"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM prompt:**\n",
       "```text\n",
       "You are an assistant that writes article paragraphs.\n",
       "Write a clear, readable article paragraph (around 150-300 words) based on the following outline:\n",
       "- Benefits: how smartphones support seniors through social connection, telehealth, medication reminders, and emergency alerts.\n",
       "\n",
       "- Health risks and mitigations: address eye strain, sleep disruption, and posture issues with accessibility settings, blue-light filters, larger text, and regular breaks.\n",
       "\n",
       "- Practical guidelines for adoption: recommend senior-friendly devices and apps, voice assistants, clear onboarding, and ongoing tech support with caregiver involvement.\n",
       "\n",
       "- Safety, privacy, and support: emphasize data privacy, scam awareness, built-in safety features (fall detection, SOS), and access to local training resources.\n",
       "Keep language neutral and suitable for a general audience.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM response:**\n",
       "```text\n",
       "Smartphones can play a meaningful role in aging-in-place by broadening social connection, enabling telehealth, reminding about medications, and triggering emergency alerts. With a tap, seniors can stay in touch with family, friends, and support networks through calls, video chats, and messaging, reducing isolation. Telehealth appointments become more convenient, saving trips to clinics and allowing remote monitoring. Medication reminders, daily schedules, and refill alerts help adherence, while emergency features like SOS and fall detection can summon help quickly. At the same time, health risks deserve attention. Eye strain, sleep disruption from late-evening notifications, and poor posture can be mitigated through accessibility settings, blue-light filters, larger text and icons, high-contrast modes, and reminders to take breaks. Practical adoption guidelines include choosing senior-friendly devices and apps with simple home screens and large controls, using voice assistants to minimize tapping, providing clear onboarding with step-by-step setup instructions, and ensuring ongoing tech support that involves caregivers and family members. Safety and privacy are essential: review app permissions, choose devices with strong security updates, stay vigilant against scams, and use built-in safety features such as fall detection and SOS. Finally, connect with local resources—training sessions at community centers, libraries, or hospitals—and leverage caregiver involvement to sustain confidence and independence in using smartphones.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Draft (stored to state):**\n",
       "\n",
       "```text\n",
       "Smartphones can play a meaningful role in aging-in-place by broadening social connection, enabling telehealth, reminding about medications, and triggering emergency alerts. With a tap, seniors can stay in touch with family, friends, and support networks through calls, video chats, and messaging, reducing isolation. Telehealth appointments become more convenient, saving trips to clinics and allowing remote monitoring. Medication reminders, daily schedules, and refill alerts help adherence, while emergency features like SOS and fall detection can summon help quickly. At the same time, health risks deserve attention. Eye strain, sleep disruption from late-evening notifications, and poor posture can be mitigated through accessibility settings, blue-light filters, larger text and icons, high-contrast modes, and reminders to take breaks. Practical adoption guidelines include choosing senior-friendly devices and apps with simple home screens and large controls, using voice assistants to minimize tapping, providing clear onboarding with step-by-step setup instructions, and ensuring ongoing tech support that involves caregivers and family members. Safety and privacy are essential: review app permissions, choose devices with strong security updates, stay vigilant against scams, and use built-in safety features such as fall detection and SOS. Finally, connect with local resources—training sessions at community centers, libraries, or hospitals—and leverage caregiver involvement to sustain confidence and independence in using smartphones.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Node: refine_draft — refining draft into ‘New Scientist’ style"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM prompt:**\n",
       "```text\n",
       "You are an editor for a popular science magazine (New Scientist style).\n",
       "Rewrite the provided draft to be concise, engaging, and accessible to a general audience.\n",
       "Keep scientific accuracy, use clear explanations and a slightly journalistic tone, and avoid jargon where possible.\n",
       "Limit the refined draft to about 150-250 words.\n",
       "\n",
       "Outline:\n",
       "- Benefits: how smartphones support seniors through social connection, telehealth, medication reminders, and emergency alerts.\n",
       "\n",
       "- Health risks and mitigations: address eye strain, sleep disruption, and posture issues with accessibility settings, blue-light filters, larger text, and regular breaks.\n",
       "\n",
       "- Practical guidelines for adoption: recommend senior-friendly devices and apps, voice assistants, clear onboarding, and ongoing tech support with caregiver involvement.\n",
       "\n",
       "- Safety, privacy, and support: emphasize data privacy, scam awareness, built-in safety features (fall detection, SOS), and access to local training resources.\n",
       "\n",
       "Draft:\n",
       "Smartphones can play a meaningful role in aging-in-place by broadening social connection, enabling telehealth, reminding about medications, and triggering emergency alerts. With a tap, seniors can stay in touch with family, friends, and support networks through calls, video chats, and messaging, reducing isolation. Telehealth appointments become more convenient, saving trips to clinics and allowing remote monitoring. Medication reminders, daily schedules, and refill alerts help adherence, while emergency features like SOS and fall detection can summon help quickly. At the same time, health risks deserve attention. Eye strain, sleep disruption from late-evening notifications, and poor posture can be mitigated through accessibility settings, blue-light filters, larger text and icons, high-contrast modes, and reminders to take breaks. Practical adoption guidelines include choosing senior-friendly devices and apps with simple home screens and large controls, using voice assistants to minimize tapping, providing clear onboarding with step-by-step setup instructions, and ensuring ongoing tech support that involves caregivers and family members. Safety and privacy are essential: review app permissions, choose devices with strong security updates, stay vigilant against scams, and use built-in safety features such as fall detection and SOS. Finally, connect with local resources—training sessions at community centers, libraries, or hospitals—and leverage caregiver involvement to sustain confidence and independence in using smartphones.\n",
       "\n",
       "Return only the refined article text (no extra commentary).\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM response:**\n",
       "```text\n",
       "Smartphones can help seniors age in place by expanding social ties, enabling telehealth, nudging medication schedules, and triggering emergency alerts. A tap keeps family and friends connected through calls, video chats, and messages, easing loneliness. Telehealth apps cut trips to clinics and let remote monitoring keep doctors in the loop. Medication reminders, daily schedules, and refill alerts support adherence, while SOS and fall-detection features summon help fast when it’s needed.\n",
       "\n",
       "But there are health risks to manage. Eye strain, sleep disruption from late notifications, and poor posture can be mitigated with accessibility settings: larger text and icons, high-contrast themes, blue-light filters, and built‑in reminders to take breaks. Regular screen-free periods and appropriate brightness help, too.\n",
       "\n",
       "Practical adoption is smoother with senior-friendly choices. Look for devices and apps with simplified home screens and large controls, and use voice assistants to minimize tapping. Provide clear onboarding with step-by-step setup, and arrange ongoing tech support that involves caregivers or family members.\n",
       "\n",
       "Safety, privacy, and support matter as well. Review app permissions, keep devices updated, and stay vigilant against scams. Rely on built-in safety features like fall detection and SOS, and connect with local training resources at community centers, libraries, or hospitals to sustain confidence and independence.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Refined draft (stored to state):**\n",
       "\n",
       "```text\n",
       "Smartphones can help seniors age in place by expanding social ties, enabling telehealth, nudging medication schedules, and triggering emergency alerts. A tap keeps family and friends connected through calls, video chats, and messages, easing loneliness. Telehealth apps cut trips to clinics and let remote monitoring keep doctors in the loop. Medication reminders, daily schedules, and refill alerts support adherence, while SOS and fall-detection features summon help fast when it’s needed.\n",
       "\n",
       "But there are health risks to manage. Eye strain, sleep disruption from late notifications, and poor posture can be mitigated with accessibility settings: larger text and icons, high-contrast themes, blue-light filters, and built‑in reminders to take breaks. Regular screen-free periods and appropriate brightness help, too.\n",
       "\n",
       "Practical adoption is smoother with senior-friendly choices. Look for devices and apps with simplified home screens and large controls, and use voice assistants to minimize tapping. Provide clear onboarding with step-by-step setup, and arrange ongoing tech support that involves caregivers or family members.\n",
       "\n",
       "Safety, privacy, and support matter as well. Review app permissions, keep devices updated, and stay vigilant against scams. Rely on built-in safety features like fall detection and SOS, and connect with local training resources at community centers, libraries, or hospitals to sustain confidence and independence.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Final state (summary)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Topic:\n",
       "\n",
       "**elderly smartphone usage and health**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Outline:\n",
       "\n",
       "```text\n",
       "- Benefits: how smartphones support seniors through social connection, telehealth, medication reminders, and emergency alerts.\n",
       "\n",
       "- Health risks and mitigations: address eye strain, sleep disruption, and posture issues with accessibility settings, blue-light filters, larger text, and regular breaks.\n",
       "\n",
       "- Practical guidelines for adoption: recommend senior-friendly devices and apps, voice assistants, clear onboarding, and ongoing tech support with caregiver involvement.\n",
       "\n",
       "- Safety, privacy, and support: emphasize data privacy, scam awareness, built-in safety features (fall detection, SOS), and access to local training resources.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Draft:\n",
       "\n",
       "```text\n",
       "Smartphones can play a meaningful role in aging-in-place by broadening social connection, enabling telehealth, reminding about medications, and triggering emergency alerts. With a tap, seniors can stay in touch with family, friends, and support networks through calls, video chats, and messaging, reducing isolation. Telehealth appointments become more convenient, saving trips to clinics and allowing remote monitoring. Medication reminders, daily schedules, and refill alerts help adherence, while emergency features like SOS and fall detection can summon help quickly. At the same time, health risks deserve attention. Eye strain, sleep disruption from late-evening notifications, and poor posture can be mitigated through accessibility settings, blue-light filters, larger text and icons, high-contrast modes, and reminders to take breaks. Practical adoption guidelines include choosing senior-friendly devices and apps with simple home screens and large controls, using voice assistants to minimize tapping, providing clear onboarding with step-by-step setup instructions, and ensuring ongoing tech support that involves caregivers and family members. Safety and privacy are essential: review app permissions, choose devices with strong security updates, stay vigilant against scams, and use built-in safety features such as fall detection and SOS. Finally, connect with local resources—training sessions at community centers, libraries, or hospitals—and leverage caregiver involvement to sustain confidence and independence in using smartphones.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Refined Draft (New Scientist style):\n",
       "\n",
       "```text\n",
       "Smartphones can help seniors age in place by expanding social ties, enabling telehealth, nudging medication schedules, and triggering emergency alerts. A tap keeps family and friends connected through calls, video chats, and messages, easing loneliness. Telehealth apps cut trips to clinics and let remote monitoring keep doctors in the loop. Medication reminders, daily schedules, and refill alerts support adherence, while SOS and fall-detection features summon help fast when it’s needed.\n",
       "\n",
       "But there are health risks to manage. Eye strain, sleep disruption from late notifications, and poor posture can be mitigated with accessibility settings: larger text and icons, high-contrast themes, blue-light filters, and built‑in reminders to take breaks. Regular screen-free periods and appropriate brightness help, too.\n",
       "\n",
       "Practical adoption is smoother with senior-friendly choices. Look for devices and apps with simplified home screens and large controls, and use voice assistants to minimize tapping. Provide clear onboarding with step-by-step setup, and arrange ongoing tech support that involves caregivers or family members.\n",
       "\n",
       "Safety, privacy, and support matter as well. Review app permissions, keep devices updated, and stay vigilant against scams. Rely on built-in safety features like fall detection and SOS, and connect with local training resources at community centers, libraries, or hospitals to sustain confidence and independence.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Process log (LLM calls in order)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Step 1** — stored response length: 630 chars"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Step 2** — stored response length: 1551 chars"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Step 3** — stored response length: 1442 chars"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "Run complete."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from colorama import Fore, Style\n",
    "\n",
    "from camel.societies import RolePlaying\n",
    "from camel.utils import print_text_animated\n",
    "\n",
    "# ========= 你的初始化（原封不动） =========\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY not set in environment. Please set it before running this notebook.\")\n",
    "\n",
    "# 注意：你强调的 base url\n",
    "base_url = os.getenv(\"OPENAI_API_BASE\", \"https://xiaoai.plus/v1\")\n",
    "model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-5-mini\")\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "process_log = []\n",
    "\n",
    "# ========= 只做“适配”，不重建 client =========\n",
    "# 不同 camel-ai 版本导入路径可能略有差异，这里做兼容导入\n",
    "try:\n",
    "    from camel.models import OpenAIModel\n",
    "except Exception:\n",
    "    from camel.models.openai_model import OpenAIModel\n",
    "\n",
    "# 这里不需要你再配置 base_url\n",
    "# base_url 已经在 client 里了\n",
    "camel_model = OpenAIModel(\n",
    "    model_type=model_name,\n",
    "    client=client,                # 关键：注入你现成的 client\n",
    "    model_config_dict=None,       # 关键：不额外配一堆 config，走默认\n",
    ")\n",
    "\n",
    "# ========= CAMEL 角色设定 =========\n",
    "assistant_role = \"无厘头科普写手\"\n",
    "user_role = \"科学审稿人\"\n",
    "\n",
    "assistant_prompt = (\n",
    "    \"你负责写无厘头科普，允许夸张和离谱比喻。\"\n",
    "    \"只能在表达上胡来，事实必须正确。\"\n",
    "    \"输出中文。\"\n",
    ")\n",
    "\n",
    "user_prompt = (\n",
    "    \"你是严格科学审稿人。\"\n",
    "    \"指出事实错误、含混和可能误导的表达，并给出明确可执行的改写要求。\"\n",
    "    \"输出中文，用条目列出。\"\n",
    ")\n",
    "\n",
    "# Compatibility wrapper for RolePlaying constructor\n",
    "def build_role_playing_compatible(**kwargs):\n",
    "    \"\"\"Try multiple common kwarg-name variants for RolePlaying constructor.\"\"\"\n",
    "    import inspect, traceback\n",
    "    attempts = [\n",
    "        # variant used in some examples\n",
    "        [\"assistant_role_name\",\"user_role_name\",\"assistant_role_prompt\",\"user_role_prompt\",\"model\"],\n",
    "        # some versions use assistant_prompt/user_prompt\n",
    "        [\"assistant_role_name\",\"user_role_name\",\"assistant_prompt\",\"user_prompt\",\"model\"],\n",
    "        # some versions expect assistant_role and user_role dicts\n",
    "        [\"assistant_role\",\"user_role\",\"model\"],\n",
    "        # some possible shortened names\n",
    "        [\"assistant_name\",\"user_name\",\"assistant_prompt\",\"user_prompt\",\"model\"],\n",
    "        # bare minimal\n",
    "        [\"assistant_role_name\",\"user_role_name\",\"model\"],\n",
    "    ]\n",
    "\n",
    "    last_exc = None\n",
    "    for keys in attempts:\n",
    "        kwargs_try = {k: v for k, v in kwargs.items() if k in keys}\n",
    "        try:\n",
    "            rp = RolePlaying(**kwargs_try)\n",
    "            print(\"RolePlaying succeeded with keys:\", sorted(list(kwargs_try.keys())))\n",
    "            return rp\n",
    "        except TypeError as e:\n",
    "            last_exc = e\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "            traceback.print_exc()\n",
    "\n",
    "    # If not successful, raise informative error with signature\n",
    "    sig = inspect.signature(RolePlaying.__init__)\n",
    "    raise TypeError(f\"All attempts failed. Last exception: {last_exc}.\\nRolePlaying.__init__ signature: {sig}\")\n",
    "\n",
    "# Build role_playing using compatibility wrapper\n",
    "role_playing = build_role_playing_compatible(\n",
    "    assistant_role_name=assistant_role,\n",
    "    user_role_name=user_role,\n",
    "    assistant_role_prompt=assistant_prompt,\n",
    "    user_role_prompt=user_prompt,\n",
    "    model=camel_model,\n",
    ")\n",
    "\n",
    "# ========= 启动对话 =========\n",
    "topic = \"为什么人会打喷嚏\"\n",
    "initial_prompt = f\"主题：{topic}\\n请写一段 300 到 400 字的无厘头科普草稿。\"\n",
    "\n",
    "assistant_msg, user_msg = role_playing.init_chat(initial_prompt)\n",
    "\n",
    "print_text_animated(Fore.GREEN + \"=== 初稿（无厘头写手） ===\\n\" + Style.RESET_ALL)\n",
    "print_text_animated(assistant_msg.content)\n",
    "\n",
    "# 记录日志，方便你学习回看\n",
    "process_log.append({\"stage\": \"draft\", \"text\": assistant_msg.content})\n",
    "\n",
    "# ========= 多轮审稿与重写 =========\n",
    "rounds = 3\n",
    "for i in range(rounds):\n",
    "    print_text_animated(Fore.CYAN + f\"\\n=== 第 {i+1} 轮：科学审稿 ===\\n\" + Style.RESET_ALL)\n",
    "    assistant_msg, user_msg = role_playing.step(assistant_msg)\n",
    "    print_text_animated(user_msg.content)\n",
    "    process_log.append({\"stage\": f\"review_{i+1}\", \"text\": user_msg.content})\n",
    "\n",
    "    print_text_animated(Fore.GREEN + f\"\\n=== 第 {i+1} 轮：无厘头重写 ===\\n\" + Style.RESET_ALL)\n",
    "    assistant_msg, user_msg = role_playing.step(user_msg)\n",
    "    print_text_animated(assistant_msg.content)\n",
    "    process_log.append({\"stage\": f\"rewrite_{i+1}\", \"text\": assistant_msg.content})\n",
    "\n",
    "print_text_animated(Fore.YELLOW + \"\\n=== 最终版本（可发布） ===\\n\" + Style.RESET_ALL)\n",
    "print_text_animated(assistant_msg.content)\n",
    "process_log.append({\"stage\": \"final\", \"text\": assistant_msg.content})\n",
    "    display(Markdown(\"**Draft (stored to state):**\\n\\n\" + (\"```text\\n\" + draft + \"\\n```\" if draft else \"(empty)\")))\n",
    "\n",
    "    return {\"draft\": draft}\n",
    "\n",
    "\n",
    "def refine_draft(state: ArticleState) -> ArticleState:\n",
    "    \"\"\"Refine the existing draft into a 'New Scientist' style: concise, engaging, lightly journalistic but scientifically grounded.\"\"\"\n",
    "    draft = state.get(\"draft\", \"\")\n",
    "    outline = state.get(\"outline\", \"\")\n",
    "    display(Markdown(\"### Node: refine_draft — refining draft into ‘New Scientist’ style\"))\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an editor for a popular science magazine (New Scientist style).\\n\"\n",
    "        \"Rewrite the provided draft to be concise, engaging, and accessible to a general audience.\\n\"\n",
    "        \"Keep scientific accuracy, use clear explanations and a slightly journalistic tone, and avoid jargon where possible.\\n\"\n",
    "        \"Limit the refined draft to about 150-250 words.\\n\\n\"\n",
    "        f\"Outline:\\n{outline}\\n\\nDraft:\\n{draft}\\n\\n\"\n",
    "        \"Return only the refined article text (no extra commentary).\"\n",
    "    )\n",
    "\n",
    "    refined = call_llm(prompt)\n",
    "\n",
    "    display(Markdown(\"**Refined draft (stored to state):**\\n\\n\" + (\"```text\\n\" + refined + \"\\n```\" if refined else \"(empty)\")))\n",
    "\n",
    "    return {\"refined_draft\": refined}\n",
    "\n",
    "\n",
    "# 3️⃣ 构建 Graph\n",
    "def build_graph():\n",
    "    graph = StateGraph(ArticleState)\n",
    "\n",
    "    graph.add_node(\"outline\", make_outline)\n",
    "    graph.add_node(\"draft\", write_draft)\n",
    "    graph.add_node(\"refine\", refine_draft)\n",
    "\n",
    "    graph.set_entry_point(\"outline\")\n",
    "    graph.add_edge(\"outline\", \"draft\")\n",
    "    graph.add_edge(\"draft\", \"refine\")\n",
    "    graph.add_edge(\"refine\", END)\n",
    "\n",
    "    return graph.compile()\n",
    "\n",
    "\n",
    "# 4️⃣ 运行（示例）\n",
    "if __name__ == \"__main__\":\n",
    "    app = build_graph()\n",
    "\n",
    "    initial_state = {\"topic\": \"elderly smartphone usage and health\"}\n",
    "\n",
    "    display(Markdown(\"## Running the agent graph\"))\n",
    "    display(Markdown(\"**Initial state:**\\n\\n```json\\n\" + str(initial_state) + \"\\n```\"))\n",
    "\n",
    "    final_state = app.invoke(initial_state)\n",
    "\n",
    "    # Present final state as Markdown for better readability\n",
    "    display(Markdown(\"## Final state (summary)\"))\n",
    "    topic = final_state.get(\"topic\", initial_state.get(\"topic\", \"(none)\"))\n",
    "    outline = final_state.get(\"outline\", \"(none)\")\n",
    "    draft = final_state.get(\"draft\", \"(none)\")\n",
    "    refined = final_state.get(\"refined_draft\", \"(none)\")\n",
    "\n",
    "    display(Markdown(f\"### Topic:\\n\\n**{topic}**\"))\n",
    "    display(Markdown(\"### Outline:\\n\\n\" + (\"```text\\n\" + outline + \"\\n```\" if outline else \"(none)\")))\n",
    "    display(Markdown(\"### Draft:\\n\\n\" + (\"```text\\n\" + draft + \"\\n```\" if draft else \"(none)\")))\n",
    "    display(Markdown(\"### Refined Draft (New Scientist style):\\n\\n\" + (\"```text\\n\" + refined + \"\\n```\" if refined else \"(none)\")))\n",
    "\n",
    "    # Optionally show the process log as an ordered list\n",
    "    display(Markdown(\"## Process log (LLM calls in order)\"))\n",
    "    for i, entry in enumerate(process_log, 1):\n",
    "        resp_len = len(entry.get('response') or \"\")\n",
    "        display(Markdown(f\"**Step {i}** — stored response length: {resp_len} chars\"))\n",
    "\n",
    "    display(Markdown(\"---\\nRun complete.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2554161c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-30 22:23:12,210 - camel.societies.role_playing - WARNING - Model provided globally is set for all agents if not already specified in agent_kwargs.\n",
      "RolePlaying instantiated with assistant_role_name/user_role_name + model\n",
      "DIAGNOSTIC: type(res)= <class 'camel.messages.base.BaseMessage'>\n",
      "DIAGNOSTIC: repr(res)[:500]= BaseMessage(role_name='无厘头科普写手', role_type=<RoleType.ASSISTANT: 'assistant'>, meta_dict=None, content='主题：为什么人会打喷嚏\\n请写一段 300 到 400 字的无厘头科普草稿。', video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None, reasoning_content=None)\n",
      "DIAGNOSTIC: res.content repr[:500]= '主题：为什么人会打喷嚏\\n请写一段 300 到 400 字的无厘头科普草稿。'\n",
      "DIAGNOSTIC: type(assistant_text)= <class 'str'>\n",
      "DIAGNOSTIC: len(assistant_text)= 37\n",
      "DIAGNOSTIC: repr(assistant_text)[:500]= '主题：为什么人会打喷嚏\\n请写一段 300 到 400 字的无厘头科普草稿。'\n",
      "DIAGNOSTIC: first 200 chars=\n",
      "主题：为什么人会打喷嚏\n",
      "请写一段 300 到 400 字的无厘头科普草稿。\n",
      "DIAGNOSTIC: ords (first 80)= [20027, 39064, 65306, 20026, 20160, 20040, 20154, 20250, 25171, 21943, 22159, 10, 35831, 20889, 19968, 27573, 32, 51, 48, 48, 32, 21040, 32, 52, 48, 48, 32, 23383, 30340, 26080, 21400, 22836, 31185, 26222, 33609, 31295, 12290]\n",
      "DIAGNOSTIC: every-char-duplicated (sample)= False\n",
      "DIAGNOSTIC: no obvious every-char duplication detected in sample\n",
      "\u001b[32m=== 初稿（无厘头写手） ===\n",
      "\u001b[0m主题：为什么人会打喷嚏\n",
      "请写一段 300 到 400 字的无厘头科普草稿。\u001b[36m\n",
      "=== 第 1 轮：科学审稿 ===\n",
      "\u001b[0mInstruction: 请用英文撰写一篇恰好50个英文单词的无厘头科普短文，主题为“为什么人会打喷嚏”，面向普通读者。核心发现要用恰好三个日常物品作比喻；包含一个潜在应用；指出一个表达上的改进点；语气轻松、非误导、尽量少用专业术语；并附上一个简短的题注。Input: None\u001b[32m\n",
      "=== 第 1 轮：无厘头重写 ===\n",
      "\u001b[0mSolution: \n",
      "Explanation and plan:\n",
      "- Task: craft a 50-word English piece explaining \"Why do people sneeze\" for a general audience.\n",
      "- Constraints: three everyday objects as metaphors (pepper shaker, napkin, umbrella); one potential application; one articulation improvement; light tone; minimal jargon; attach a brief caption; exactly 50 words in the main piece; separate caption.\n",
      "- Final structure: 50-word main piece, then a short caption.\n",
      "\n",
      "Main piece (50 words):\n",
      "Why do we sneeze? It's a nose reflex when irritants invade. A pepper shaker shakes loose trouble, a napkin swats away invaders, and an umbrella blocks a rain of particles in the air. Application: smarter allergy sprays. Improvement: choose clearer words to describe the reflex. More relatable, less jargon, please.\n",
      "\n",
      "Caption: Sneezes decoded with everyday props.\n",
      "Next request.\u001b[36m\n",
      "=== 第 2 轮：科学审稿 ===\n",
      "\u001b[0m<CAMEL_TASK_DONE>\u001b[32m\n",
      "=== 第 2 轮：无厘头重写 ===\n",
      "\u001b[0mSolution: Completed. I confirm that the 50-word main piece and caption were delivered earlier as requested. If you want fresh variants, I can generate new 50-word pieces using different triplets of everyday objects, plus a new application and articulation note. Here’s a ready-to-use toolkit to reuse:\n",
      "\n",
      "- Triplet options (three objects each)\n",
      "  1) pepper shaker; napkin; umbrella\n",
      "  2) balloon; scarf; door\n",
      "  3) coffee mug; tissue; fan\n",
      "\n",
      "- Fill-in skeleton for a new piece\n",
      "  Why do we sneeze? It's a nose reflex when irritants invade. A [O1] [V1], a [O2] [V2], and a [O3] [V3] air. Application: [X]. Improvement: [Y]. Caption: [C].\n",
      "\n",
      "- Example verbs/phrases (to mix and match)\n",
      "  V1: shakes loose trouble, V2: swats away invaders, V3: blocks a rain of particles\n",
      "  X: smarter allergy sprays, Y: choose clearer wording, C: Sneezes decoded with everyday props\n",
      "\n",
      "If you’d like, specify objects or vibe, and I’ll produce a fresh 50-word piece with exact word count. Next request.\u001b[36m\n",
      "=== 第 3 轮：科学审稿 ===\n",
      "\u001b[0mInstruction: From the three object triplets below, pick one and write a brand-new 50-word English piece explaining \"Why do we sneeze\" for a general audience. Use the chosen triplet as three metaphors for the core finding; include one potential application and one articulation improvement point; keep a light, non-misleading tone with minimal jargon; attach a brief caption. Output: main piece (exactly 50 words) and caption. Input: None\u001b[32m\n",
      "=== 第 3 轮：无厘头重写 ===\n",
      "\u001b[0mSolution: \n",
      "Explanation: The three object triplets were not provided in this prompt. To proceed, I’ll select the pepper shaker, napkin, and umbrella triplet as a default. If you prefer another trio, paste them and I’ll regenerate.\n",
      "\n",
      "Main piece (50 words):\n",
      "Why do we sneeze? It’s a nose reflex when irritants invade. A pepper shaker jolts loose trouble, a napkin clears the air, and an umbrella shields us from a rain of particles. Application: smarter allergy sprays. Improvement: use crisper terms for the reflex, keeping it friendly and clear. For readers.\n",
      "\n",
      "Caption: Sneezes decoded with pepper, napkin, and umbrella.\n",
      "Next request.\u001b[33m\n",
      "=== 最终版本（可发布） ===\n",
      "\u001b[0mSolution: \n",
      "Explanation: The three object triplets were not provided in this prompt. To proceed, I’ll select the pepper shaker, napkin, and umbrella triplet as a default. If you prefer another trio, paste them and I’ll regenerate.\n",
      "\n",
      "Main piece (50 words):\n",
      "Why do we sneeze? It’s a nose reflex when irritants invade. A pepper shaker jolts loose trouble, a napkin clears the air, and an umbrella shields us from a rain of particles. Application: smarter allergy sprays. Improvement: use crisper terms for the reflex, keeping it friendly and clear. For readers.\n",
      "\n",
      "Caption: Sneezes decoded with pepper, napkin, and umbrella.\n",
      "Next request."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from colorama import Fore, Style\n",
    "\n",
    "# Try to import RolePlaying and helper; different camel versions may expose paths differently\n",
    "try:\n",
    "    from camel.societies import RolePlaying\n",
    "    from camel.utils import print_text_animated\n",
    "except Exception:\n",
    "    # re-raise a clearer error if import fails\n",
    "    raise\n",
    "\n",
    "# ========= 你的初始化（原封不动） =========\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY not set in environment. Please set it before running this notebook.\")\n",
    "\n",
    "# 注意：你强调的 base url\n",
    "base_url = os.getenv(\"OPENAI_API_BASE\", \"https://xiaoai.plus/v1\")\n",
    "model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-5-mini\")\n",
    "\n",
    "# reuse existing OpenAI client if present; else construct a minimal one\n",
    "try:\n",
    "    client\n",
    "except NameError:\n",
    "    client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "process_log = []\n",
    "\n",
    "# If camel provides OpenAIModel, try to wrap the client; otherwise we'll pass the model name directly\n",
    "camel_model = None\n",
    "try:\n",
    "    try:\n",
    "        from camel.models import OpenAIModel\n",
    "    except Exception:\n",
    "        from camel.models.openai_model import OpenAIModel\n",
    "    camel_model = OpenAIModel(model_type=model_name, client=client, model_config_dict=None)\n",
    "except Exception:\n",
    "    # Not fatal; we'll attempt to pass model_name directly to RolePlaying if accepted\n",
    "    camel_model = None\n",
    "\n",
    "# ========= CAMEL 角色设定 =========\n",
    "assistant_role = \"无厘头科普写手\"\n",
    "user_role = \"科学审稿人\"\n",
    "\n",
    "assistant_prompt = (\n",
    "    \"你负责写无厘头科普，允许夸张和离谱比喻。\"\n",
    "    \"只能在表达上胡来，事实必须正确。\"\n",
    "    \"输出中文。\"\n",
    ")\n",
    "\n",
    "user_prompt = (\n",
    "    \"你是严格科学审稿人。\"\n",
    "    \"指出事实错误、含混和可能误导的表达，并给出明确可执行的改写要求。\"\n",
    "    \"输出中文，用条目列出。\"\n",
    ")\n",
    "\n",
    "# Robust RolePlaying construction: try a few common signatures without passing unsupported keys\n",
    "role_playing = None\n",
    "last_exc = None\n",
    "\n",
    "# Attempt 1: common named args (some versions accept assistant_role_name + assistant_prompt)\n",
    "try:\n",
    "    kwargs = {\n",
    "        \"assistant_role_name\": assistant_role,\n",
    "        \"user_role_name\": user_role,\n",
    "        \"assistant_prompt\": assistant_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "    }\n",
    "    if camel_model is not None:\n",
    "        kwargs[\"model\"] = camel_model\n",
    "    else:\n",
    "        kwargs[\"model\"] = model_name\n",
    "    role_playing = RolePlaying(**kwargs)\n",
    "    print(\"RolePlaying instantiated with assistant_prompt/user_prompt variant\")\n",
    "except TypeError as e:\n",
    "    last_exc = e\n",
    "\n",
    "# Attempt 2: some versions expect assistant_role_name + user_role_name + model only\n",
    "if role_playing is None:\n",
    "    try:\n",
    "        kwargs = {\n",
    "            \"assistant_role_name\": assistant_role,\n",
    "            \"user_role_name\": user_role,\n",
    "        }\n",
    "        if camel_model is not None:\n",
    "            kwargs[\"model\"] = camel_model\n",
    "        else:\n",
    "            kwargs[\"model\"] = model_name\n",
    "        role_playing = RolePlaying(**kwargs)\n",
    "        print(\"RolePlaying instantiated with assistant_role_name/user_role_name + model\")\n",
    "    except TypeError as e:\n",
    "        last_exc = e\n",
    "\n",
    "# Attempt 3: dict-style roles (some versions use assistant_role/user_role dicts)\n",
    "if role_playing is None:\n",
    "    try:\n",
    "        assistant_role_dict = {\"name\": assistant_role, \"prompt\": assistant_prompt}\n",
    "        user_role_dict = {\"name\": user_role, \"prompt\": user_prompt}\n",
    "        kwargs = {\"assistant_role\": assistant_role_dict, \"user_role\": user_role_dict}\n",
    "        if camel_model is not None:\n",
    "            kwargs[\"model\"] = camel_model\n",
    "        else:\n",
    "            kwargs[\"model\"] = model_name\n",
    "        role_playing = RolePlaying(**kwargs)\n",
    "        print(\"RolePlaying instantiated with assistant_role/user_role dicts\")\n",
    "    except TypeError as e:\n",
    "        last_exc = e\n",
    "\n",
    "# Attempt 4: try minimal bare model-only init\n",
    "if role_playing is None:\n",
    "    try:\n",
    "        role_playing = RolePlaying(model=camel_model if camel_model is not None else model_name)\n",
    "        print(\"RolePlaying instantiated with model-only argument\")\n",
    "    except Exception as e:\n",
    "        last_exc = e\n",
    "\n",
    "if role_playing is None:\n",
    "    # Provide a helpful error message including the last exception\n",
    "    raise TypeError(f\"Failed to construct RolePlaying. Last exception: {last_exc}\")\n",
    "\n",
    "# ========= 启动对话 =========\n",
    "topic = \"为什么人会打喷嚏\"\n",
    "initial_prompt = f\"主题：{topic}\\n请写一段 300 到 400 字的无厘头科普草稿。\"\n",
    "\n",
    "# Helpers to extract plain text from various return objects\n",
    "import types\n",
    "\n",
    "def _get_content(obj):\n",
    "    \"\"\"Return a text string extracted from obj. Works for str, objects with .content, dicts, and camel ChatAgentResponse-like objects with .msgs.\"\"\"\n",
    "    if obj is None:\n",
    "        return None\n",
    "    if isinstance(obj, str):\n",
    "        return obj\n",
    "    # objects with .content\n",
    "    if hasattr(obj, \"content\") and isinstance(obj.content, str):\n",
    "        return obj.content\n",
    "    # dict-like\n",
    "    if isinstance(obj, dict):\n",
    "        for key in (\"content\", \"text\", \"message\", \"msg\"):\n",
    "            if key in obj and isinstance(obj[key], str):\n",
    "                return obj[key]\n",
    "        return str(obj)\n",
    "    # camel ChatAgentResponse has .msgs (list); each item may have .content\n",
    "    if hasattr(obj, \"msgs\") and isinstance(obj.msgs, (list, tuple)):\n",
    "        for m in obj.msgs:\n",
    "            if hasattr(m, \"content\") and isinstance(m.content, str):\n",
    "                return m.content\n",
    "        # fallback to stringifying first element\n",
    "        try:\n",
    "            return str(obj.msgs[0])\n",
    "        except Exception:\n",
    "            return str(obj)\n",
    "    # nested attribute 'message'\n",
    "    if hasattr(obj, \"message\") and hasattr(obj.message, \"content\"):\n",
    "        return obj.message.content\n",
    "    # fallback\n",
    "    try:\n",
    "        return str(obj)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _normalize_pair_to_contents(result):\n",
    "    \"\"\"Return tuple of (assistant_text, user_text) both plain strings (either may be None).\n",
    "    Accepts: tuple/list, single message-like object, dict, or object with msgs.\n",
    "    \"\"\"\n",
    "    # tuple/list\n",
    "    if isinstance(result, (tuple, list)):\n",
    "        if len(result) >= 2:\n",
    "            return _get_content(result[0]), _get_content(result[1])\n",
    "        elif len(result) == 1:\n",
    "            return _get_content(result[0]), None\n",
    "    # single\n",
    "    return _get_content(result), None\n",
    "\n",
    "\n",
    "# Call init_chat and extract plain text\n",
    "res = role_playing.init_chat(initial_prompt)\n",
    "# --- Diagnostic block: inspect raw response and detect obvious duplication patterns ---\n",
    "import unicodedata\n",
    "# show a compact repr and type for the raw response object (may be Message, tuple, dict, etc.)\n",
    "print('DIAGNOSTIC: type(res)=', type(res))\n",
    "try:\n",
    "    print('DIAGNOSTIC: repr(res)[:500]=', repr(res)[:500])\n",
    "except Exception as _e:\n",
    "    print('DIAGNOSTIC: repr(res) failed:', _e)\n",
    "# if the object has msgs/content, show a bit more detail\n",
    "if hasattr(res, 'msgs'):\n",
    "    try:\n",
    "        print('DIAGNOSTIC: res.msgs length=', len(res.msgs))\n",
    "        for i, m in enumerate(res.msgs[:3]):\n",
    "            print(f' DIAGNOSTIC: msg[{i}] type={type(m)}')\n",
    "            if hasattr(m, 'content'):\n",
    "                print('   DIAGNOSTIC: msg.content repr[:200]=', repr(m.content)[:200])\n",
    "    except Exception as _e:\n",
    "        print('DIAGNOSTIC: inspecting res.msgs failed:', _e)\n",
    "if hasattr(res, 'content'):\n",
    "    try:\n",
    "        print('DIAGNOSTIC: res.content repr[:500]=', repr(res.content)[:500])\n",
    "    except Exception as _e:\n",
    "        print('DIAGNOSTIC: inspecting res.content failed:', _e)\n",
    "# Normalize/extract plain strings into assistant_text/user_text using existing helper\n",
    "assistant_text, user_text = _normalize_pair_to_contents(res)\n",
    "# More diagnostics on the extracted assistant_text (if any)\n",
    "if assistant_text is None:\n",
    "    print('DIAGNOSTIC: assistant_text is None')\n",
    "else:\n",
    "    print('DIAGNOSTIC: type(assistant_text)=', type(assistant_text))\n",
    "    try:\n",
    "        print('DIAGNOSTIC: len(assistant_text)=', len(assistant_text))\n",
    "        print('DIAGNOSTIC: repr(assistant_text)[:500]=', repr(assistant_text)[:500])\n",
    "        print('DIAGNOSTIC: first 200 chars=')\n",
    "        print(assistant_text[:200])\n",
    "        print('DIAGNOSTIC: ords (first 80)=', list(map(ord, assistant_text[:80])))\n",
    "    except Exception as _e:\n",
    "        print('DIAGNOSTIC: assistant_text inspection failed:', _e)\n",
    "# quick helper: detect if every character appears doubled (aa bb cc -> aabbcc pattern)\n",
    "def is_every_char_duplicated(s, check_pairs=500):\n",
    "    if not s:\n",
    "        return False\n",
    "    pairs = min(check_pairs, len(s)//2)\n",
    "    if pairs == 0:\n",
    "        return False\n",
    "    for i in range(0, pairs*2, 2):\n",
    "        if s[i] != s[i+1]:\n",
    "            return False\n",
    "    return True\n",
    "# safe dedupe helper: if every-char duplicated use s[::2], else collapse runs to single chars (lossy but conservative)\n",
    "def dedupe_if_obvious_double(s):\n",
    "    if is_every_char_duplicated(s, check_pairs=500):\n",
    "        return s[::2]\n",
    "    # collapse runs: keep first of each run (avoids regex/backslash escaping issues in notebook JSON)\n",
    "    out = []\n",
    "    prev = None\n",
    "    for ch in s:\n",
    "        if ch != prev:\n",
    "            out.append(ch)\n",
    "            prev = ch\n",
    "    return ''.join(out)\n",
    "# check pattern and show a sample of the deduped output (do NOT modify original text yet)\n",
    "if assistant_text:\n",
    "    duplicated = is_every_char_duplicated(assistant_text, check_pairs=500)\n",
    "    print('DIAGNOSTIC: every-char-duplicated (sample)=', duplicated)\n",
    "    if duplicated:\n",
    "        print('DIAGNOSTIC: sample deduped (first 400 chars)=')\n",
    "        print(dedupe_if_obvious_double(assistant_text)[:400])\n",
    "    else:\n",
    "        print('DIAGNOSTIC: no obvious every-char duplication detected in sample')\n",
    "\n",
    "# Print assistant initial draft if available\n",
    "if assistant_text:\n",
    "    print_text_animated(Fore.GREEN + \"=== 初稿（无厘头写手） ===\\n\" + Style.RESET_ALL)\n",
    "    print_text_animated(assistant_text)\n",
    "    process_log.append({\"stage\": \"draft\", \"text\": assistant_text})\n",
    "else:\n",
    "    print_text_animated(Fore.YELLOW + \"(No assistant initial message returned)\" + Style.RESET_ALL)\n",
    "\n",
    "# ========= 多轮审稿与重写 =========\n",
    "rounds = 3\n",
    "for i in range(rounds):\n",
    "    # REVIEW: pass plain text into step to avoid MemoryRecord validation errors\n",
    "    prev_for_review_text = assistant_text if assistant_text else user_text\n",
    "    res = role_playing.step(prev_for_review_text)\n",
    "    assistant_text_r, user_text_r = _normalize_pair_to_contents(res)\n",
    "\n",
    "    # If a user_text was returned, treat that as the review output to print\n",
    "    if user_text_r:\n",
    "        print_text_animated(Fore.CYAN + f\"\\n=== 第 {i+1} 轮：科学审稿 ===\\n\" + Style.RESET_ALL)\n",
    "        print_text_animated(user_text_r)\n",
    "        process_log.append({\"stage\": f\"review_{i+1}\", \"text\": user_text_r})\n",
    "    else:\n",
    "        # If only assistant-like message returned, print it as reviewer output (best-effort)\n",
    "        if assistant_text_r:\n",
    "            print_text_animated(Fore.CYAN + f\"\\n=== 第 {i+1} 轮：科学审稿 (single-message) ===\\n\" + Style.RESET_ALL)\n",
    "            print_text_animated(assistant_text_r)\n",
    "            process_log.append({\"stage\": f\"review_{i+1}\", \"text\": assistant_text_r})\n",
    "\n",
    "    # For rewrite, call step with the most recent user_text if present, else assistant_text\n",
    "    prev_for_rewrite_text = user_text_r if user_text_r else assistant_text_r if assistant_text_r else (user_text or assistant_text)\n",
    "    res2 = role_playing.step(prev_for_rewrite_text)\n",
    "    assistant_text2, user_text2 = _normalize_pair_to_contents(res2)\n",
    "\n",
    "    if assistant_text2:\n",
    "        print_text_animated(Fore.GREEN + f\"\\n=== 第 {i+1} 轮：无厘头重写 ===\\n\" + Style.RESET_ALL)\n",
    "        print_text_animated(assistant_text2)\n",
    "        process_log.append({\"stage\": f\"rewrite_{i+1}\", \"text\": assistant_text2})\n",
    "\n",
    "    # update the main assistant_text/user_text for next round\n",
    "    assistant_text, user_text = assistant_text2 or assistant_text_r or assistant_text, user_text2 or user_text_r or user_text\n",
    "\n",
    "print_text_animated(Fore.YELLOW + \"\\n=== 最终版本（可发布） ===\\n\" + Style.RESET_ALL)\n",
    "if assistant_text:\n",
    "    print_text_animated(assistant_text)\n",
    "    process_log.append({\"stage\": \"final\", \"text\": assistant_text})\n",
    "else:\n",
    "    print_text_animated(Fore.YELLOW + \"(No final assistant message)\" + Style.RESET_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841eb3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-30 23:50:50,132 - camel.societies.role_playing - WARNING - Model provided globally is set for all agents if not already specified in agent_kwargs.\n",
      "\u001b[36m具体任务描述:\n",
      "创作一篇无厘头风格但科学准确的科普短文，主题是“为什么人会打喷嚏”。\n",
      "\n",
      "要求：\n",
      "1. 中文写作，全文五段，总字数 300–400 字\n",
      "2. 明确解释喷嚏的生理机制，包括：\n",
      "   - 刺激物\n",
      "   - 鼻腔黏膜感受器\n",
      "   - 三叉神经\n",
      "   - 脑干喷嚏中枢\n",
      "   - 喷嚏的防御意义\n",
      "3. 科学事实准确，不编造因果关系\n",
      "4. 风格允许离谱比喻和拟人，但不得使用“机场”“消防广播”“求救信号”“入侵者”等老套比喻\n",
      "5. 语言生动、有记忆点，适合普通读者理解\n",
      "\n",
      "\u001b[34m科学审稿人 (AI User):\n",
      "\n",
      "Instruction: 请你先给出这篇短文的结构与要点提纲，确保五段，总字数在300–400字，明确覆盖刺激物、鼻腔黏膜感受器、三叉神经、脑干喷嚏中枢，以及喷嚏的防御意义，并用生动但科学的语言设计记忆点。  \n",
      "Input: None\n",
      "\u001b[32m无厘头科普写手 (AI Assistant):\n",
      "\n",
      "Solution: 下面给出这篇五段结构的要点提纲，目标总字数约300–400字，确保覆盖刺激物、鼻腔黏膜感受器、三叉神经、脑干喷嚏中枢，以及喷嚏的防御意义，并设计生动的记忆点与拟人化表述。字数分配建议：每段约66–70字，总计约330–350字，便于后续直接落到文章写作上。\n",
      "\n",
      "段落一要点（刺激物与触发情景）\n",
      "- 要点描述：列举常见刺激物如粉尘、花粉、烟雾、香水分子等，描述它们进入鼻腔引发“警报”的瞬间场景。\n",
      "- 记忆点/拟人化：把刺激物想象成“探照灯队列”一一照亮鼻腔的暗处。\n",
      "- 写作提示：可以日常情景开场，逐步引出鼻腔反应的初始信号。\n",
      "\n",
      "段落二要点（鼻腔黏膜感受器）\n",
      "- 要点描述：鼻腔黏膜上分布的感受器捕捉化学刺激，包含化学受体与离子通道（如TRP家族）参与的信号转导，形成初步的神经信号。\n",
      "- 记忆点/拟人化：感受器是鼻腔的“报警器”被触发，发出报警信号。\n",
      "- 写作提示：强调感受器的化学敏感性与“先天警觉”性质，避免超越科学边界的夸张。\n",
      "\n",
      "段落三要点（三叉神经传导）\n",
      "- 要点描述：感受器信号通过三叉神经末梢传入中枢，描述大致传导路径（鼻部分支→脑干核区的信号汇聚）。\n",
      "- 记忆点/拟人化：三叉神经是“交通警”的信号传递员，把警报送往大脑。\n",
      "- 写作提示：用简明比喻展现传导的速度与方向性，避免过度技术化。\n",
      "\n",
      "段落四要点（脑干喷嚏中枢与喷嚏动作序列）\n",
      "- 要点描述：脑干喷嚏中枢接收信号，协调吸气、喉部闭合、胸腹肌群的爆发性喷出，完成一次喷嚏。\n",
      "- 记忆点/拟人化：中枢像“指挥官”下达喷出的命令，肌群像乐队齐奏。\n",
      "- 写作提示：描绘动作顺序的连贯性，突出防御性的生理目的。\n",
      "\n",
      "段落五要点（喷嚏的防御意义）\n",
      "- 要点描述：喷嚏作为防御反射，清除鼻腔内 irritants，保护呼吸道，但也可能带来传播与尴尬等社会后果。\n",
      "- 记忆点/拟人化：喷嚏是鼻腔的“清道夫/守卫”，虽偶有尴尬但实乃保卫机制。\n",
      "- 写作提示：点出科学意义与现实影响，保持客观，避免与夸张叙述混淆。\n",
      "\n",
      "可直接使用的句式模板（帮助落到字数目标）\n",
      "- 开场模板（段落一）：当某些微小粒子迈入鼻腔，空气仿佛被点亮，警报随之响起，刺激物像一队队探照灯队伍在鼻腔里巡游。\n",
      "- 过程模板（段落二、三、四）：鼻腔黏膜的感受器像细密的报警网，TRP通道接过信号，三叉神经担任传令官，最终脑干指挥官发出喷嚏指令，肌肉群齐声响应。\n",
      "- 结论模板（段落五）：喷嚏是一种古老而高效的防御反射，既帮助清除刺激物，也提醒我们鼻腔在默默保护我们呼吸道。\n",
      "\n",
      "Next request.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from colorama import Fore\n",
    "\n",
    "from camel.societies import RolePlaying\n",
    "from camel.utils import print_text_animated\n",
    "from camel.models import OpenAIModel\n",
    "from camel.messages import BaseMessage\n",
    "\n",
    "\n",
    "# ========= 你的初始化（保持你的 base_url 与 client） =========\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY not set in environment. Please set it before running this notebook.\")\n",
    "\n",
    "base_url = os.getenv(\"OPENAI_API_BASE\", \"https://xiaoai.plus/v1\")\n",
    "model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-5-mini\")\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "# ========= 注入 CAMEL（复用你的 client，不让 CAMEL 自己走默认 endpoint） =========\n",
    "model = OpenAIModel(\n",
    "    model_type=model_name,\n",
    "    client=client,\n",
    "    model_config_dict=None,\n",
    ")\n",
    "\n",
    "# ========= 任务 prompt：按你给的“模板思路”把流程写清楚 =========\n",
    "# 关键：RolePlaying 旧版接口不支持 assistant_role_prompt/user_role_prompt，所以规则都放 task_prompt\n",
    "task_prompt_template = \"\"\"\n",
    "创作一篇无厘头风格但科学准确的科普短文，主题是“为什么人会打喷嚏”。\n",
    "\n",
    "要求：\n",
    "1. 中文写作，全文五段，总字数 300–400 字\n",
    "2. 明确解释喷嚏的生理机制，包括：\n",
    "   - 刺激物\n",
    "   - 鼻腔黏膜感受器\n",
    "   - 三叉神经\n",
    "   - 脑干喷嚏中枢\n",
    "   - 喷嚏的防御意义\n",
    "3. 科学事实准确，不编造因果关系\n",
    "4. 风格允许离谱比喻和拟人，但不得使用“机场”“消防广播”“求救信号”“入侵者”等老套比喻\n",
    "5. 语言生动、有记忆点，适合普通读者理解\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def run(topic: str = \"为什么人会打喷嚏\", chat_turn_limit: int = 20, finalize_turn: int = 12) -> None:\n",
    "    # 初始化角色扮演会话（完全照你给的模板结构）\n",
    "    role_play_session = RolePlaying(\n",
    "        assistant_role_name=\"无厘头科普写手\",\n",
    "        user_role_name=\"科学审稿人\",\n",
    "        model=model,  # 关键：让 RolePlaying 的 agents 用你注入的 model\n",
    "        task_prompt=task_prompt_template.format(topic=topic),\n",
    "        with_task_specify=False,\n",
    "    )\n",
    "\n",
    "    print(Fore.CYAN + f\"具体任务描述:\\n{role_play_session.task_prompt}\\n\")\n",
    "\n",
    "    n = 0\n",
    "    input_msg = role_play_session.init_chat()\n",
    "\n",
    "    while n < chat_turn_limit:\n",
    "        n += 1\n",
    "\n",
    "        # 在某一轮强制触发最终输出（防止审稿人一直不给 <CAMEL_TASK_DONE>）\n",
    "        # 这一步是“更新我们原来的代码”的关键：不靠模型自觉收尾\n",
    "        if n == finalize_turn:\n",
    "            input_msg = BaseMessage.make_user_message(\n",
    "                role_name=\"科学审稿人\",\n",
    "                content=(\n",
    "                    \"FINALIZE\\n\"\n",
    "                    \"请作为无厘头科普写手输出最终可发布版本。\\n\"\n",
    "                    \"要求：中文五段，总字数300到400字，科学点齐全，风格无厘头但不胡编，禁用比喻词依旧生效。\\n\"\n",
    "                    \"只输出正文，末尾追加 <CAMEL_TASK_DONE>。\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        assistant_response, user_response = role_play_session.step(input_msg)\n",
    "\n",
    "        if assistant_response.msg is None or user_response.msg is None:\n",
    "            break\n",
    "\n",
    "        # 注意：按你模板的打印顺序\n",
    "        # user_response 是 “AI User” = 科学审稿人\n",
    "        # assistant_response 是 “AI Assistant” = 无厘头科普写手\n",
    "        print_text_animated(Fore.BLUE + f\"科学审稿人 (AI User):\\n\\n{user_response.msg.content}\\n\")\n",
    "        print_text_animated(Fore.GREEN + f\"无厘头科普写手 (AI Assistant):\\n\\n{assistant_response.msg.content}\\n\")\n",
    "\n",
    "        # 任务完成标志\n",
    "        if \"<CAMEL_TASK_DONE>\" in user_response.msg.content or \"<CAMEL_TASK_DONE>\" in assistant_response.msg.content:\n",
    "            print(Fore.MAGENTA + \"✅ 科普短文完成！\")\n",
    "            break\n",
    "\n",
    "        # 将助理（写手）的回复作为下一轮输入（照你模板）\n",
    "        input_msg = assistant_response.msg\n",
    "\n",
    "    print(Fore.YELLOW + f\"总共进行了 {n} 轮协作对话\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run(topic=\"为什么人会打喷嚏\", chat_turn_limit=20, finalize_turn=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec6df12",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16617e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
