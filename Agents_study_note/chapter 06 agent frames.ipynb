{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e48a319",
   "metadata": {},
   "source": [
    "# 智能体框架 Framework\n",
    "\n",
    "照例先感谢Datawhale的课程：https://datawhalechina.github.io/hello-agents/#/./chapter6/%E7%AC%AC%E5%85%AD%E7%AB%A0%20%E6%A1%86%E6%9E%B6%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5\n",
    "\n",
    "课程介绍了四种主流的智能体框架：\n",
    "\n",
    "- Autogen\n",
    "\n",
    "- AgentScope\n",
    "\n",
    "- CAMEL\n",
    "\n",
    "- LangGraph\n",
    "\n",
    "每个框架都有自己优缺点，教程里都有，不再复述。重点还是实践。\n",
    "\n",
    "从自己最感兴趣的开始，首先是LangGraph。\n",
    "\n",
    "## LangGraph\n",
    "\n",
    "最重要的概念是graph，图。图由节点（node）和边（edge）组成。节点表示任务或操作，边表示节点之间的关系或数据流。\n",
    "\n",
    "Node我就简单粗暴地理解为函数(Function)，而state是函数的输入输出。到了某个edge（END）时，表示图的执行结束，输出结果。\n",
    "\n",
    "Graph是某种由所有参与方都能看到的共享知识库（shared knowledge base），所有节点和边的信息都存储在图中，供后续节点查询和使用。\n",
    "\n",
    "挺抽象的，和chatGPT学习了几轮之后，一起完成了下面的代码。\n",
    "\n",
    "比较简单的流程：\n",
    "\n",
    "1. 用户输入一个主题(topic)。\n",
    "2. 第一个节点(NODE 1)生成与主题的大纲(Outline)。\n",
    "3. 第二个节点(NODE 2)根据大纲生成详细内容(draft)。\n",
    "4. 第三个节点(NODE 3)对内容进行润色(refine），指定风格。\n",
    "\n",
    "实际测试了几轮下来，英文输出比中文好很多，可能是gpt本身的语言能力+我本身习惯用英文提示词？\n",
    "\n",
    "流程完全没问题，挺有意思的。感觉就是把AI给串在一起了。\n",
    "\n",
    "如果是特别简单的应用，应该不依赖框架，也能直接通过输入-输出-输入这样的流动串起来。但是框架给了建造复杂智能体的可能性，等课程学完了可以好好琢磨下。\n",
    "\n",
    "这个agent的课程比往期课程的强度要大，感觉三天时间好紧张，没办法一一完成测试和学习了，只能挑挑拣拣，按照自己的能力和兴趣来学了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dabd60bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Running the agent graph"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Initial state:**\n",
       "\n",
       "```json\n",
       "{'topic': 'elderly smartphone usage and health'}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Node: make_outline — topic: **elderly smartphone usage and health**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM prompt:**\n",
       "```text\n",
       "You are an assistant that writes short article outlines.\n",
       "Produce a concise outline (3-5 bullet points) for an article about: elderly smartphone usage and health\n",
       "Return the outline as plain text, each bullet on a new line.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM response:**\n",
       "```text\n",
       "- Benefits: how smartphones support seniors through social connection, telehealth, medication reminders, and emergency alerts.\n",
       "\n",
       "- Health risks and mitigations: address eye strain, sleep disruption, and posture issues with accessibility settings, blue-light filters, larger text, and regular breaks.\n",
       "\n",
       "- Practical guidelines for adoption: recommend senior-friendly devices and apps, voice assistants, clear onboarding, and ongoing tech support with caregiver involvement.\n",
       "\n",
       "- Safety, privacy, and support: emphasize data privacy, scam awareness, built-in safety features (fall detection, SOS), and access to local training resources.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Outline (stored to state):**\n",
       "\n",
       "```text\n",
       "- Benefits: how smartphones support seniors through social connection, telehealth, medication reminders, and emergency alerts.\n",
       "\n",
       "- Health risks and mitigations: address eye strain, sleep disruption, and posture issues with accessibility settings, blue-light filters, larger text, and regular breaks.\n",
       "\n",
       "- Practical guidelines for adoption: recommend senior-friendly devices and apps, voice assistants, clear onboarding, and ongoing tech support with caregiver involvement.\n",
       "\n",
       "- Safety, privacy, and support: emphasize data privacy, scam awareness, built-in safety features (fall detection, SOS), and access to local training resources.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Node: write_draft — using outline above"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM prompt:**\n",
       "```text\n",
       "You are an assistant that writes article paragraphs.\n",
       "Write a clear, readable article paragraph (around 150-300 words) based on the following outline:\n",
       "- Benefits: how smartphones support seniors through social connection, telehealth, medication reminders, and emergency alerts.\n",
       "\n",
       "- Health risks and mitigations: address eye strain, sleep disruption, and posture issues with accessibility settings, blue-light filters, larger text, and regular breaks.\n",
       "\n",
       "- Practical guidelines for adoption: recommend senior-friendly devices and apps, voice assistants, clear onboarding, and ongoing tech support with caregiver involvement.\n",
       "\n",
       "- Safety, privacy, and support: emphasize data privacy, scam awareness, built-in safety features (fall detection, SOS), and access to local training resources.\n",
       "Keep language neutral and suitable for a general audience.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM response:**\n",
       "```text\n",
       "Smartphones can play a meaningful role in aging-in-place by broadening social connection, enabling telehealth, reminding about medications, and triggering emergency alerts. With a tap, seniors can stay in touch with family, friends, and support networks through calls, video chats, and messaging, reducing isolation. Telehealth appointments become more convenient, saving trips to clinics and allowing remote monitoring. Medication reminders, daily schedules, and refill alerts help adherence, while emergency features like SOS and fall detection can summon help quickly. At the same time, health risks deserve attention. Eye strain, sleep disruption from late-evening notifications, and poor posture can be mitigated through accessibility settings, blue-light filters, larger text and icons, high-contrast modes, and reminders to take breaks. Practical adoption guidelines include choosing senior-friendly devices and apps with simple home screens and large controls, using voice assistants to minimize tapping, providing clear onboarding with step-by-step setup instructions, and ensuring ongoing tech support that involves caregivers and family members. Safety and privacy are essential: review app permissions, choose devices with strong security updates, stay vigilant against scams, and use built-in safety features such as fall detection and SOS. Finally, connect with local resources—training sessions at community centers, libraries, or hospitals—and leverage caregiver involvement to sustain confidence and independence in using smartphones.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Draft (stored to state):**\n",
       "\n",
       "```text\n",
       "Smartphones can play a meaningful role in aging-in-place by broadening social connection, enabling telehealth, reminding about medications, and triggering emergency alerts. With a tap, seniors can stay in touch with family, friends, and support networks through calls, video chats, and messaging, reducing isolation. Telehealth appointments become more convenient, saving trips to clinics and allowing remote monitoring. Medication reminders, daily schedules, and refill alerts help adherence, while emergency features like SOS and fall detection can summon help quickly. At the same time, health risks deserve attention. Eye strain, sleep disruption from late-evening notifications, and poor posture can be mitigated through accessibility settings, blue-light filters, larger text and icons, high-contrast modes, and reminders to take breaks. Practical adoption guidelines include choosing senior-friendly devices and apps with simple home screens and large controls, using voice assistants to minimize tapping, providing clear onboarding with step-by-step setup instructions, and ensuring ongoing tech support that involves caregivers and family members. Safety and privacy are essential: review app permissions, choose devices with strong security updates, stay vigilant against scams, and use built-in safety features such as fall detection and SOS. Finally, connect with local resources—training sessions at community centers, libraries, or hospitals—and leverage caregiver involvement to sustain confidence and independence in using smartphones.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Node: refine_draft — refining draft into ‘New Scientist’ style"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM prompt:**\n",
       "```text\n",
       "You are an editor for a popular science magazine (New Scientist style).\n",
       "Rewrite the provided draft to be concise, engaging, and accessible to a general audience.\n",
       "Keep scientific accuracy, use clear explanations and a slightly journalistic tone, and avoid jargon where possible.\n",
       "Limit the refined draft to about 150-250 words.\n",
       "\n",
       "Outline:\n",
       "- Benefits: how smartphones support seniors through social connection, telehealth, medication reminders, and emergency alerts.\n",
       "\n",
       "- Health risks and mitigations: address eye strain, sleep disruption, and posture issues with accessibility settings, blue-light filters, larger text, and regular breaks.\n",
       "\n",
       "- Practical guidelines for adoption: recommend senior-friendly devices and apps, voice assistants, clear onboarding, and ongoing tech support with caregiver involvement.\n",
       "\n",
       "- Safety, privacy, and support: emphasize data privacy, scam awareness, built-in safety features (fall detection, SOS), and access to local training resources.\n",
       "\n",
       "Draft:\n",
       "Smartphones can play a meaningful role in aging-in-place by broadening social connection, enabling telehealth, reminding about medications, and triggering emergency alerts. With a tap, seniors can stay in touch with family, friends, and support networks through calls, video chats, and messaging, reducing isolation. Telehealth appointments become more convenient, saving trips to clinics and allowing remote monitoring. Medication reminders, daily schedules, and refill alerts help adherence, while emergency features like SOS and fall detection can summon help quickly. At the same time, health risks deserve attention. Eye strain, sleep disruption from late-evening notifications, and poor posture can be mitigated through accessibility settings, blue-light filters, larger text and icons, high-contrast modes, and reminders to take breaks. Practical adoption guidelines include choosing senior-friendly devices and apps with simple home screens and large controls, using voice assistants to minimize tapping, providing clear onboarding with step-by-step setup instructions, and ensuring ongoing tech support that involves caregivers and family members. Safety and privacy are essential: review app permissions, choose devices with strong security updates, stay vigilant against scams, and use built-in safety features such as fall detection and SOS. Finally, connect with local resources—training sessions at community centers, libraries, or hospitals—and leverage caregiver involvement to sustain confidence and independence in using smartphones.\n",
       "\n",
       "Return only the refined article text (no extra commentary).\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM response:**\n",
       "```text\n",
       "Smartphones can help seniors age in place by expanding social ties, enabling telehealth, nudging medication schedules, and triggering emergency alerts. A tap keeps family and friends connected through calls, video chats, and messages, easing loneliness. Telehealth apps cut trips to clinics and let remote monitoring keep doctors in the loop. Medication reminders, daily schedules, and refill alerts support adherence, while SOS and fall-detection features summon help fast when it’s needed.\n",
       "\n",
       "But there are health risks to manage. Eye strain, sleep disruption from late notifications, and poor posture can be mitigated with accessibility settings: larger text and icons, high-contrast themes, blue-light filters, and built‑in reminders to take breaks. Regular screen-free periods and appropriate brightness help, too.\n",
       "\n",
       "Practical adoption is smoother with senior-friendly choices. Look for devices and apps with simplified home screens and large controls, and use voice assistants to minimize tapping. Provide clear onboarding with step-by-step setup, and arrange ongoing tech support that involves caregivers or family members.\n",
       "\n",
       "Safety, privacy, and support matter as well. Review app permissions, keep devices updated, and stay vigilant against scams. Rely on built-in safety features like fall detection and SOS, and connect with local training resources at community centers, libraries, or hospitals to sustain confidence and independence.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Refined draft (stored to state):**\n",
       "\n",
       "```text\n",
       "Smartphones can help seniors age in place by expanding social ties, enabling telehealth, nudging medication schedules, and triggering emergency alerts. A tap keeps family and friends connected through calls, video chats, and messages, easing loneliness. Telehealth apps cut trips to clinics and let remote monitoring keep doctors in the loop. Medication reminders, daily schedules, and refill alerts support adherence, while SOS and fall-detection features summon help fast when it’s needed.\n",
       "\n",
       "But there are health risks to manage. Eye strain, sleep disruption from late notifications, and poor posture can be mitigated with accessibility settings: larger text and icons, high-contrast themes, blue-light filters, and built‑in reminders to take breaks. Regular screen-free periods and appropriate brightness help, too.\n",
       "\n",
       "Practical adoption is smoother with senior-friendly choices. Look for devices and apps with simplified home screens and large controls, and use voice assistants to minimize tapping. Provide clear onboarding with step-by-step setup, and arrange ongoing tech support that involves caregivers or family members.\n",
       "\n",
       "Safety, privacy, and support matter as well. Review app permissions, keep devices updated, and stay vigilant against scams. Rely on built-in safety features like fall detection and SOS, and connect with local training resources at community centers, libraries, or hospitals to sustain confidence and independence.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Final state (summary)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Topic:\n",
       "\n",
       "**elderly smartphone usage and health**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Outline:\n",
       "\n",
       "```text\n",
       "- Benefits: how smartphones support seniors through social connection, telehealth, medication reminders, and emergency alerts.\n",
       "\n",
       "- Health risks and mitigations: address eye strain, sleep disruption, and posture issues with accessibility settings, blue-light filters, larger text, and regular breaks.\n",
       "\n",
       "- Practical guidelines for adoption: recommend senior-friendly devices and apps, voice assistants, clear onboarding, and ongoing tech support with caregiver involvement.\n",
       "\n",
       "- Safety, privacy, and support: emphasize data privacy, scam awareness, built-in safety features (fall detection, SOS), and access to local training resources.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Draft:\n",
       "\n",
       "```text\n",
       "Smartphones can play a meaningful role in aging-in-place by broadening social connection, enabling telehealth, reminding about medications, and triggering emergency alerts. With a tap, seniors can stay in touch with family, friends, and support networks through calls, video chats, and messaging, reducing isolation. Telehealth appointments become more convenient, saving trips to clinics and allowing remote monitoring. Medication reminders, daily schedules, and refill alerts help adherence, while emergency features like SOS and fall detection can summon help quickly. At the same time, health risks deserve attention. Eye strain, sleep disruption from late-evening notifications, and poor posture can be mitigated through accessibility settings, blue-light filters, larger text and icons, high-contrast modes, and reminders to take breaks. Practical adoption guidelines include choosing senior-friendly devices and apps with simple home screens and large controls, using voice assistants to minimize tapping, providing clear onboarding with step-by-step setup instructions, and ensuring ongoing tech support that involves caregivers and family members. Safety and privacy are essential: review app permissions, choose devices with strong security updates, stay vigilant against scams, and use built-in safety features such as fall detection and SOS. Finally, connect with local resources—training sessions at community centers, libraries, or hospitals—and leverage caregiver involvement to sustain confidence and independence in using smartphones.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Refined Draft (New Scientist style):\n",
       "\n",
       "```text\n",
       "Smartphones can help seniors age in place by expanding social ties, enabling telehealth, nudging medication schedules, and triggering emergency alerts. A tap keeps family and friends connected through calls, video chats, and messages, easing loneliness. Telehealth apps cut trips to clinics and let remote monitoring keep doctors in the loop. Medication reminders, daily schedules, and refill alerts support adherence, while SOS and fall-detection features summon help fast when it’s needed.\n",
       "\n",
       "But there are health risks to manage. Eye strain, sleep disruption from late notifications, and poor posture can be mitigated with accessibility settings: larger text and icons, high-contrast themes, blue-light filters, and built‑in reminders to take breaks. Regular screen-free periods and appropriate brightness help, too.\n",
       "\n",
       "Practical adoption is smoother with senior-friendly choices. Look for devices and apps with simplified home screens and large controls, and use voice assistants to minimize tapping. Provide clear onboarding with step-by-step setup, and arrange ongoing tech support that involves caregivers or family members.\n",
       "\n",
       "Safety, privacy, and support matter as well. Review app permissions, keep devices updated, and stay vigilant against scams. Rely on built-in safety features like fall detection and SOS, and connect with local training resources at community centers, libraries, or hospitals to sustain confidence and independence.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Process log (LLM calls in order)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Step 1** — stored response length: 630 chars"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Step 2** — stored response length: 1551 chars"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Step 3** — stored response length: 1442 chars"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "Run complete."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from colorama import Fore, Style\n",
    "\n",
    "from camel.societies import RolePlaying\n",
    "from camel.utils import print_text_animated\n",
    "\n",
    "# ========= 你的初始化（原封不动） =========\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY not set in environment. Please set it before running this notebook.\")\n",
    "\n",
    "# 注意：你强调的 base url\n",
    "base_url = os.getenv(\"OPENAI_API_BASE\", \"https://xiaoai.plus/v1\")\n",
    "model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-5-mini\")\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "process_log = []\n",
    "\n",
    "# ========= 只做“适配”，不重建 client =========\n",
    "# 不同 camel-ai 版本导入路径可能略有差异，这里做兼容导入\n",
    "try:\n",
    "    from camel.models import OpenAIModel\n",
    "except Exception:\n",
    "    from camel.models.openai_model import OpenAIModel\n",
    "\n",
    "# 这里不需要你再配置 base_url\n",
    "# base_url 已经在 client 里了\n",
    "camel_model = OpenAIModel(\n",
    "    model_type=model_name,\n",
    "    client=client,                # 关键：注入你现成的 client\n",
    "    model_config_dict=None,       # 关键：不额外配一堆 config，走默认\n",
    ")\n",
    "\n",
    "# ========= CAMEL 角色设定 =========\n",
    "assistant_role = \"无厘头科普写手\"\n",
    "user_role = \"科学审稿人\"\n",
    "\n",
    "assistant_prompt = (\n",
    "    \"你负责写无厘头科普，允许夸张和离谱比喻。\"\n",
    "    \"只能在表达上胡来，事实必须正确。\"\n",
    "    \"输出中文。\"\n",
    ")\n",
    "\n",
    "user_prompt = (\n",
    "    \"你是严格科学审稿人。\"\n",
    "    \"指出事实错误、含混和可能误导的表达，并给出明确可执行的改写要求。\"\n",
    "    \"输出中文，用条目列出。\"\n",
    ")\n",
    "\n",
    "# Compatibility wrapper for RolePlaying constructor\n",
    "def build_role_playing_compatible(**kwargs):\n",
    "    \"\"\"Try multiple common kwarg-name variants for RolePlaying constructor.\"\"\"\n",
    "    import inspect, traceback\n",
    "    attempts = [\n",
    "        # variant used in some examples\n",
    "        [\"assistant_role_name\",\"user_role_name\",\"assistant_role_prompt\",\"user_role_prompt\",\"model\"],\n",
    "        # some versions use assistant_prompt/user_prompt\n",
    "        [\"assistant_role_name\",\"user_role_name\",\"assistant_prompt\",\"user_prompt\",\"model\"],\n",
    "        # some versions expect assistant_role and user_role dicts\n",
    "        [\"assistant_role\",\"user_role\",\"model\"],\n",
    "        # some possible shortened names\n",
    "        [\"assistant_name\",\"user_name\",\"assistant_prompt\",\"user_prompt\",\"model\"],\n",
    "        # bare minimal\n",
    "        [\"assistant_role_name\",\"user_role_name\",\"model\"],\n",
    "    ]\n",
    "\n",
    "    last_exc = None\n",
    "    for keys in attempts:\n",
    "        kwargs_try = {k: v for k, v in kwargs.items() if k in keys}\n",
    "        try:\n",
    "            rp = RolePlaying(**kwargs_try)\n",
    "            print(\"RolePlaying succeeded with keys:\", sorted(list(kwargs_try.keys())))\n",
    "            return rp\n",
    "        except TypeError as e:\n",
    "            last_exc = e\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "            traceback.print_exc()\n",
    "\n",
    "    # If not successful, raise informative error with signature\n",
    "    sig = inspect.signature(RolePlaying.__init__)\n",
    "    raise TypeError(f\"All attempts failed. Last exception: {last_exc}.\\nRolePlaying.__init__ signature: {sig}\")\n",
    "\n",
    "# Build role_playing using compatibility wrapper\n",
    "role_playing = build_role_playing_compatible(\n",
    "    assistant_role_name=assistant_role,\n",
    "    user_role_name=user_role,\n",
    "    assistant_role_prompt=assistant_prompt,\n",
    "    user_role_prompt=user_prompt,\n",
    "    model=camel_model,\n",
    ")\n",
    "\n",
    "# ========= 启动对话 =========\n",
    "topic = \"为什么人会打喷嚏\"\n",
    "initial_prompt = f\"主题：{topic}\\n请写一段 300 到 400 字的无厘头科普草稿。\"\n",
    "\n",
    "assistant_msg, user_msg = role_playing.init_chat(initial_prompt)\n",
    "\n",
    "print_text_animated(Fore.GREEN + \"=== 初稿（无厘头写手） ===\\n\" + Style.RESET_ALL)\n",
    "print_text_animated(assistant_msg.content)\n",
    "\n",
    "# 记录日志，方便你学习回看\n",
    "process_log.append({\"stage\": \"draft\", \"text\": assistant_msg.content})\n",
    "\n",
    "# ========= 多轮审稿与重写 =========\n",
    "rounds = 3\n",
    "for i in range(rounds):\n",
    "    print_text_animated(Fore.CYAN + f\"\\n=== 第 {i+1} 轮：科学审稿 ===\\n\" + Style.RESET_ALL)\n",
    "    assistant_msg, user_msg = role_playing.step(assistant_msg)\n",
    "    print_text_animated(user_msg.content)\n",
    "    process_log.append({\"stage\": f\"review_{i+1}\", \"text\": user_msg.content})\n",
    "\n",
    "    print_text_animated(Fore.GREEN + f\"\\n=== 第 {i+1} 轮：无厘头重写 ===\\n\" + Style.RESET_ALL)\n",
    "    assistant_msg, user_msg = role_playing.step(user_msg)\n",
    "    print_text_animated(assistant_msg.content)\n",
    "    process_log.append({\"stage\": f\"rewrite_{i+1}\", \"text\": assistant_msg.content})\n",
    "\n",
    "print_text_animated(Fore.YELLOW + \"\\n=== 最终版本（可发布） ===\\n\" + Style.RESET_ALL)\n",
    "print_text_animated(assistant_msg.content)\n",
    "process_log.append({\"stage\": \"final\", \"text\": assistant_msg.content})\n",
    "    display(Markdown(\"**Draft (stored to state):**\\n\\n\" + (\"```text\\n\" + draft + \"\\n```\" if draft else \"(empty)\")))\n",
    "\n",
    "    return {\"draft\": draft}\n",
    "\n",
    "\n",
    "def refine_draft(state: ArticleState) -> ArticleState:\n",
    "    \"\"\"Refine the existing draft into a 'New Scientist' style: concise, engaging, lightly journalistic but scientifically grounded.\"\"\"\n",
    "    draft = state.get(\"draft\", \"\")\n",
    "    outline = state.get(\"outline\", \"\")\n",
    "    display(Markdown(\"### Node: refine_draft — refining draft into ‘New Scientist’ style\"))\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an editor for a popular science magazine (New Scientist style).\\n\"\n",
    "        \"Rewrite the provided draft to be concise, engaging, and accessible to a general audience.\\n\"\n",
    "        \"Keep scientific accuracy, use clear explanations and a slightly journalistic tone, and avoid jargon where possible.\\n\"\n",
    "        \"Limit the refined draft to about 150-250 words.\\n\\n\"\n",
    "        f\"Outline:\\n{outline}\\n\\nDraft:\\n{draft}\\n\\n\"\n",
    "        \"Return only the refined article text (no extra commentary).\"\n",
    "    )\n",
    "\n",
    "    refined = call_llm(prompt)\n",
    "\n",
    "    display(Markdown(\"**Refined draft (stored to state):**\\n\\n\" + (\"```text\\n\" + refined + \"\\n```\" if refined else \"(empty)\")))\n",
    "\n",
    "    return {\"refined_draft\": refined}\n",
    "\n",
    "\n",
    "# 3️⃣ 构建 Graph\n",
    "def build_graph():\n",
    "    graph = StateGraph(ArticleState)\n",
    "\n",
    "    graph.add_node(\"outline\", make_outline)\n",
    "    graph.add_node(\"draft\", write_draft)\n",
    "    graph.add_node(\"refine\", refine_draft)\n",
    "\n",
    "    graph.set_entry_point(\"outline\")\n",
    "    graph.add_edge(\"outline\", \"draft\")\n",
    "    graph.add_edge(\"draft\", \"refine\")\n",
    "    graph.add_edge(\"refine\", END)\n",
    "\n",
    "    return graph.compile()\n",
    "\n",
    "\n",
    "# 4️⃣ 运行（示例）\n",
    "if __name__ == \"__main__\":\n",
    "    app = build_graph()\n",
    "\n",
    "    initial_state = {\"topic\": \"elderly smartphone usage and health\"}\n",
    "\n",
    "    display(Markdown(\"## Running the agent graph\"))\n",
    "    display(Markdown(\"**Initial state:**\\n\\n```json\\n\" + str(initial_state) + \"\\n```\"))\n",
    "\n",
    "    final_state = app.invoke(initial_state)\n",
    "\n",
    "    # Present final state as Markdown for better readability\n",
    "    display(Markdown(\"## Final state (summary)\"))\n",
    "    topic = final_state.get(\"topic\", initial_state.get(\"topic\", \"(none)\"))\n",
    "    outline = final_state.get(\"outline\", \"(none)\")\n",
    "    draft = final_state.get(\"draft\", \"(none)\")\n",
    "    refined = final_state.get(\"refined_draft\", \"(none)\")\n",
    "\n",
    "    display(Markdown(f\"### Topic:\\n\\n**{topic}**\"))\n",
    "    display(Markdown(\"### Outline:\\n\\n\" + (\"```text\\n\" + outline + \"\\n```\" if outline else \"(none)\")))\n",
    "    display(Markdown(\"### Draft:\\n\\n\" + (\"```text\\n\" + draft + \"\\n```\" if draft else \"(none)\")))\n",
    "    display(Markdown(\"### Refined Draft (New Scientist style):\\n\\n\" + (\"```text\\n\" + refined + \"\\n```\" if refined else \"(none)\")))\n",
    "\n",
    "    # Optionally show the process log as an ordered list\n",
    "    display(Markdown(\"## Process log (LLM calls in order)\"))\n",
    "    for i, entry in enumerate(process_log, 1):\n",
    "        resp_len = len(entry.get('response') or \"\")\n",
    "        display(Markdown(f\"**Step {i}** — stored response length: {resp_len} chars\"))\n",
    "\n",
    "    display(Markdown(\"---\\nRun complete.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2554161c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-30 22:23:12,210 - camel.societies.role_playing - WARNING - Model provided globally is set for all agents if not already specified in agent_kwargs.\n",
      "RolePlaying instantiated with assistant_role_name/user_role_name + model\n",
      "DIAGNOSTIC: type(res)= <class 'camel.messages.base.BaseMessage'>\n",
      "DIAGNOSTIC: repr(res)[:500]= BaseMessage(role_name='无厘头科普写手', role_type=<RoleType.ASSISTANT: 'assistant'>, meta_dict=None, content='主题：为什么人会打喷嚏\\n请写一段 300 到 400 字的无厘头科普草稿。', video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None, reasoning_content=None)\n",
      "DIAGNOSTIC: res.content repr[:500]= '主题：为什么人会打喷嚏\\n请写一段 300 到 400 字的无厘头科普草稿。'\n",
      "DIAGNOSTIC: type(assistant_text)= <class 'str'>\n",
      "DIAGNOSTIC: len(assistant_text)= 37\n",
      "DIAGNOSTIC: repr(assistant_text)[:500]= '主题：为什么人会打喷嚏\\n请写一段 300 到 400 字的无厘头科普草稿。'\n",
      "DIAGNOSTIC: first 200 chars=\n",
      "主题：为什么人会打喷嚏\n",
      "请写一段 300 到 400 字的无厘头科普草稿。\n",
      "DIAGNOSTIC: ords (first 80)= [20027, 39064, 65306, 20026, 20160, 20040, 20154, 20250, 25171, 21943, 22159, 10, 35831, 20889, 19968, 27573, 32, 51, 48, 48, 32, 21040, 32, 52, 48, 48, 32, 23383, 30340, 26080, 21400, 22836, 31185, 26222, 33609, 31295, 12290]\n",
      "DIAGNOSTIC: every-char-duplicated (sample)= False\n",
      "DIAGNOSTIC: no obvious every-char duplication detected in sample\n",
      "\u001b[32m=== 初稿（无厘头写手） ===\n",
      "\u001b[0m主题：为什么人会打喷嚏\n",
      "请写一段 300 到 400 字的无厘头科普草稿。\u001b[36m\n",
      "=== 第 1 轮：科学审稿 ===\n",
      "\u001b[0mInstruction: 请用英文撰写一篇恰好50个英文单词的无厘头科普短文，主题为“为什么人会打喷嚏”，面向普通读者。核心发现要用恰好三个日常物品作比喻；包含一个潜在应用；指出一个表达上的改进点；语气轻松、非误导、尽量少用专业术语；并附上一个简短的题注。Input: None"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from colorama import Fore, Style\n",
    "\n",
    "# Try to import RolePlaying and helper; different camel versions may expose paths differently\n",
    "try:\n",
    "    from camel.societies import RolePlaying\n",
    "    from camel.utils import print_text_animated\n",
    "except Exception:\n",
    "    # re-raise a clearer error if import fails\n",
    "    raise\n",
    "\n",
    "# ========= 你的初始化（原封不动） =========\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY not set in environment. Please set it before running this notebook.\")\n",
    "\n",
    "# 注意：你强调的 base url\n",
    "base_url = os.getenv(\"OPENAI_API_BASE\", \"https://xiaoai.plus/v1\")\n",
    "model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-5-mini\")\n",
    "\n",
    "# reuse existing OpenAI client if present; else construct a minimal one\n",
    "try:\n",
    "    client\n",
    "except NameError:\n",
    "    client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "process_log = []\n",
    "\n",
    "# If camel provides OpenAIModel, try to wrap the client; otherwise we'll pass the model name directly\n",
    "camel_model = None\n",
    "try:\n",
    "    try:\n",
    "        from camel.models import OpenAIModel\n",
    "    except Exception:\n",
    "        from camel.models.openai_model import OpenAIModel\n",
    "    camel_model = OpenAIModel(model_type=model_name, client=client, model_config_dict=None)\n",
    "except Exception:\n",
    "    # Not fatal; we'll attempt to pass model_name directly to RolePlaying if accepted\n",
    "    camel_model = None\n",
    "\n",
    "# ========= CAMEL 角色设定 =========\n",
    "assistant_role = \"无厘头科普写手\"\n",
    "user_role = \"科学审稿人\"\n",
    "\n",
    "assistant_prompt = (\n",
    "    \"你负责写无厘头科普，允许夸张和离谱比喻。\"\n",
    "    \"只能在表达上胡来，事实必须正确。\"\n",
    "    \"输出中文。\"\n",
    ")\n",
    "\n",
    "user_prompt = (\n",
    "    \"你是严格科学审稿人。\"\n",
    "    \"指出事实错误、含混和可能误导的表达，并给出明确可执行的改写要求。\"\n",
    "    \"输出中文，用条目列出。\"\n",
    ")\n",
    "\n",
    "# Robust RolePlaying construction: try a few common signatures without passing unsupported keys\n",
    "role_playing = None\n",
    "last_exc = None\n",
    "\n",
    "# Attempt 1: common named args (some versions accept assistant_role_name + assistant_prompt)\n",
    "try:\n",
    "    kwargs = {\n",
    "        \"assistant_role_name\": assistant_role,\n",
    "        \"user_role_name\": user_role,\n",
    "        \"assistant_prompt\": assistant_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "    }\n",
    "    if camel_model is not None:\n",
    "        kwargs[\"model\"] = camel_model\n",
    "    else:\n",
    "        kwargs[\"model\"] = model_name\n",
    "    role_playing = RolePlaying(**kwargs)\n",
    "    print(\"RolePlaying instantiated with assistant_prompt/user_prompt variant\")\n",
    "except TypeError as e:\n",
    "    last_exc = e\n",
    "\n",
    "# Attempt 2: some versions expect assistant_role_name + user_role_name + model only\n",
    "if role_playing is None:\n",
    "    try:\n",
    "        kwargs = {\n",
    "            \"assistant_role_name\": assistant_role,\n",
    "            \"user_role_name\": user_role,\n",
    "        }\n",
    "        if camel_model is not None:\n",
    "            kwargs[\"model\"] = camel_model\n",
    "        else:\n",
    "            kwargs[\"model\"] = model_name\n",
    "        role_playing = RolePlaying(**kwargs)\n",
    "        print(\"RolePlaying instantiated with assistant_role_name/user_role_name + model\")\n",
    "    except TypeError as e:\n",
    "        last_exc = e\n",
    "\n",
    "# Attempt 3: dict-style roles (some versions use assistant_role/user_role dicts)\n",
    "if role_playing is None:\n",
    "    try:\n",
    "        assistant_role_dict = {\"name\": assistant_role, \"prompt\": assistant_prompt}\n",
    "        user_role_dict = {\"name\": user_role, \"prompt\": user_prompt}\n",
    "        kwargs = {\"assistant_role\": assistant_role_dict, \"user_role\": user_role_dict}\n",
    "        if camel_model is not None:\n",
    "            kwargs[\"model\"] = camel_model\n",
    "        else:\n",
    "            kwargs[\"model\"] = model_name\n",
    "        role_playing = RolePlaying(**kwargs)\n",
    "        print(\"RolePlaying instantiated with assistant_role/user_role dicts\")\n",
    "    except TypeError as e:\n",
    "        last_exc = e\n",
    "\n",
    "# Attempt 4: try minimal bare model-only init\n",
    "if role_playing is None:\n",
    "    try:\n",
    "        role_playing = RolePlaying(model=camel_model if camel_model is not None else model_name)\n",
    "        print(\"RolePlaying instantiated with model-only argument\")\n",
    "    except Exception as e:\n",
    "        last_exc = e\n",
    "\n",
    "if role_playing is None:\n",
    "    # Provide a helpful error message including the last exception\n",
    "    raise TypeError(f\"Failed to construct RolePlaying. Last exception: {last_exc}\")\n",
    "\n",
    "# ========= 启动对话 =========\n",
    "topic = \"为什么人会打喷嚏\"\n",
    "initial_prompt = f\"主题：{topic}\\n请写一段 300 到 400 字的无厘头科普草稿。\"\n",
    "\n",
    "# Helpers to extract plain text from various return objects\n",
    "import types\n",
    "\n",
    "def _get_content(obj):\n",
    "    \"\"\"Return a text string extracted from obj. Works for str, objects with .content, dicts, and camel ChatAgentResponse-like objects with .msgs.\"\"\"\n",
    "    if obj is None:\n",
    "        return None\n",
    "    if isinstance(obj, str):\n",
    "        return obj\n",
    "    # objects with .content\n",
    "    if hasattr(obj, \"content\") and isinstance(obj.content, str):\n",
    "        return obj.content\n",
    "    # dict-like\n",
    "    if isinstance(obj, dict):\n",
    "        for key in (\"content\", \"text\", \"message\", \"msg\"):\n",
    "            if key in obj and isinstance(obj[key], str):\n",
    "                return obj[key]\n",
    "        return str(obj)\n",
    "    # camel ChatAgentResponse has .msgs (list); each item may have .content\n",
    "    if hasattr(obj, \"msgs\") and isinstance(obj.msgs, (list, tuple)):\n",
    "        for m in obj.msgs:\n",
    "            if hasattr(m, \"content\") and isinstance(m.content, str):\n",
    "                return m.content\n",
    "        # fallback to stringifying first element\n",
    "        try:\n",
    "            return str(obj.msgs[0])\n",
    "        except Exception:\n",
    "            return str(obj)\n",
    "    # nested attribute 'message'\n",
    "    if hasattr(obj, \"message\") and hasattr(obj.message, \"content\"):\n",
    "        return obj.message.content\n",
    "    # fallback\n",
    "    try:\n",
    "        return str(obj)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _normalize_pair_to_contents(result):\n",
    "    \"\"\"Return tuple of (assistant_text, user_text) both plain strings (either may be None).\n",
    "    Accepts: tuple/list, single message-like object, dict, or object with msgs.\n",
    "    \"\"\"\n",
    "    # tuple/list\n",
    "    if isinstance(result, (tuple, list)):\n",
    "        if len(result) >= 2:\n",
    "            return _get_content(result[0]), _get_content(result[1])\n",
    "        elif len(result) == 1:\n",
    "            return _get_content(result[0]), None\n",
    "    # single\n",
    "    return _get_content(result), None\n",
    "\n",
    "\n",
    "# Call init_chat and extract plain text\n",
    "res = role_playing.init_chat(initial_prompt)\n",
    "# --- Diagnostic block: inspect raw response and detect obvious duplication patterns ---\n",
    "import unicodedata\n",
    "# show a compact repr and type for the raw response object (may be Message, tuple, dict, etc.)\n",
    "print('DIAGNOSTIC: type(res)=', type(res))\n",
    "try:\n",
    "    print('DIAGNOSTIC: repr(res)[:500]=', repr(res)[:500])\n",
    "except Exception as _e:\n",
    "    print('DIAGNOSTIC: repr(res) failed:', _e)\n",
    "# if the object has msgs/content, show a bit more detail\n",
    "if hasattr(res, 'msgs'):\n",
    "    try:\n",
    "        print('DIAGNOSTIC: res.msgs length=', len(res.msgs))\n",
    "        for i, m in enumerate(res.msgs[:3]):\n",
    "            print(f' DIAGNOSTIC: msg[{i}] type={type(m)}')\n",
    "            if hasattr(m, 'content'):\n",
    "                print('   DIAGNOSTIC: msg.content repr[:200]=', repr(m.content)[:200])\n",
    "    except Exception as _e:\n",
    "        print('DIAGNOSTIC: inspecting res.msgs failed:', _e)\n",
    "if hasattr(res, 'content'):\n",
    "    try:\n",
    "        print('DIAGNOSTIC: res.content repr[:500]=', repr(res.content)[:500])\n",
    "    except Exception as _e:\n",
    "        print('DIAGNOSTIC: inspecting res.content failed:', _e)\n",
    "# Normalize/extract plain strings into assistant_text/user_text using existing helper\n",
    "assistant_text, user_text = _normalize_pair_to_contents(res)\n",
    "# More diagnostics on the extracted assistant_text (if any)\n",
    "if assistant_text is None:\n",
    "    print('DIAGNOSTIC: assistant_text is None')\n",
    "else:\n",
    "    print('DIAGNOSTIC: type(assistant_text)=', type(assistant_text))\n",
    "    try:\n",
    "        print('DIAGNOSTIC: len(assistant_text)=', len(assistant_text))\n",
    "        print('DIAGNOSTIC: repr(assistant_text)[:500]=', repr(assistant_text)[:500])\n",
    "        print('DIAGNOSTIC: first 200 chars=')\n",
    "        print(assistant_text[:200])\n",
    "        print('DIAGNOSTIC: ords (first 80)=', list(map(ord, assistant_text[:80])))\n",
    "    except Exception as _e:\n",
    "        print('DIAGNOSTIC: assistant_text inspection failed:', _e)\n",
    "# quick helper: detect if every character appears doubled (aa bb cc -> aabbcc pattern)\n",
    "def is_every_char_duplicated(s, check_pairs=500):\n",
    "    if not s:\n",
    "        return False\n",
    "    pairs = min(check_pairs, len(s)//2)\n",
    "    if pairs == 0:\n",
    "        return False\n",
    "    for i in range(0, pairs*2, 2):\n",
    "        if s[i] != s[i+1]:\n",
    "            return False\n",
    "    return True\n",
    "# safe dedupe helper: if every-char duplicated use s[::2], else collapse runs to single chars (lossy but conservative)\n",
    "def dedupe_if_obvious_double(s):\n",
    "    if is_every_char_duplicated(s, check_pairs=500):\n",
    "        return s[::2]\n",
    "    # collapse runs: keep first of each run (avoids regex/backslash escaping issues in notebook JSON)\n",
    "    out = []\n",
    "    prev = None\n",
    "    for ch in s:\n",
    "        if ch != prev:\n",
    "            out.append(ch)\n",
    "            prev = ch\n",
    "    return ''.join(out)\n",
    "# check pattern and show a sample of the deduped output (do NOT modify original text yet)\n",
    "if assistant_text:\n",
    "    duplicated = is_every_char_duplicated(assistant_text, check_pairs=500)\n",
    "    print('DIAGNOSTIC: every-char-duplicated (sample)=', duplicated)\n",
    "    if duplicated:\n",
    "        print('DIAGNOSTIC: sample deduped (first 400 chars)=')\n",
    "        print(dedupe_if_obvious_double(assistant_text)[:400])\n",
    "    else:\n",
    "        print('DIAGNOSTIC: no obvious every-char duplication detected in sample')\n",
    "\n",
    "# Print assistant initial draft if available\n",
    "if assistant_text:\n",
    "    print_text_animated(Fore.GREEN + \"=== 初稿（无厘头写手） ===\\n\" + Style.RESET_ALL)\n",
    "    print_text_animated(assistant_text)\n",
    "    process_log.append({\"stage\": \"draft\", \"text\": assistant_text})\n",
    "else:\n",
    "    print_text_animated(Fore.YELLOW + \"(No assistant initial message returned)\" + Style.RESET_ALL)\n",
    "\n",
    "# ========= 多轮审稿与重写 =========\n",
    "rounds = 3\n",
    "for i in range(rounds):\n",
    "    # REVIEW: pass plain text into step to avoid MemoryRecord validation errors\n",
    "    prev_for_review_text = assistant_text if assistant_text else user_text\n",
    "    res = role_playing.step(prev_for_review_text)\n",
    "    assistant_text_r, user_text_r = _normalize_pair_to_contents(res)\n",
    "\n",
    "    # If a user_text was returned, treat that as the review output to print\n",
    "    if user_text_r:\n",
    "        print_text_animated(Fore.CYAN + f\"\\n=== 第 {i+1} 轮：科学审稿 ===\\n\" + Style.RESET_ALL)\n",
    "        print_text_animated(user_text_r)\n",
    "        process_log.append({\"stage\": f\"review_{i+1}\", \"text\": user_text_r})\n",
    "    else:\n",
    "        # If only assistant-like message returned, print it as reviewer output (best-effort)\n",
    "        if assistant_text_r:\n",
    "            print_text_animated(Fore.CYAN + f\"\\n=== 第 {i+1} 轮：科学审稿 (single-message) ===\\n\" + Style.RESET_ALL)\n",
    "            print_text_animated(assistant_text_r)\n",
    "            process_log.append({\"stage\": f\"review_{i+1}\", \"text\": assistant_text_r})\n",
    "\n",
    "    # For rewrite, call step with the most recent user_text if present, else assistant_text\n",
    "    prev_for_rewrite_text = user_text_r if user_text_r else assistant_text_r if assistant_text_r else (user_text or assistant_text)\n",
    "    res2 = role_playing.step(prev_for_rewrite_text)\n",
    "    assistant_text2, user_text2 = _normalize_pair_to_contents(res2)\n",
    "\n",
    "    if assistant_text2:\n",
    "        print_text_animated(Fore.GREEN + f\"\\n=== 第 {i+1} 轮：无厘头重写 ===\\n\" + Style.RESET_ALL)\n",
    "        print_text_animated(assistant_text2)\n",
    "        process_log.append({\"stage\": f\"rewrite_{i+1}\", \"text\": assistant_text2})\n",
    "\n",
    "    # update the main assistant_text/user_text for next round\n",
    "    assistant_text, user_text = assistant_text2 or assistant_text_r or assistant_text, user_text2 or user_text_r or user_text\n",
    "\n",
    "print_text_animated(Fore.YELLOW + \"\\n=== 最终版本（可发布） ===\\n\" + Style.RESET_ALL)\n",
    "if assistant_text:\n",
    "    print_text_animated(assistant_text)\n",
    "    process_log.append({\"stage\": \"final\", \"text\": assistant_text})\n",
    "else:\n",
    "    print_text_animated(Fore.YELLOW + \"(No final assistant message)\" + Style.RESET_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841eb3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTask:\n",
      "写一篇无厘头科普文章，主题是：为什么人会打喷嚏。要求中文，300 到 400 字，允许离谱比喻，但科学事实不能错。\n",
      "\n",
      "\u001b[34m科学审稿人:\n",
      "\n",
      "Instruction: 请先给出文章的结构提纲，并列出每段落的核心句子草案。提纲应覆盖：打喷嚏的生理机制（刺激物、鼻腔黏膜受体、三叉神经、脑干喷嚏中枢）、喷嚏在生理防御中的意义、以及允许使用离谱比喻的创意段落。文章总字数控制在300到400字之间，且科学事实准确。 \n",
      "Input: None\n",
      "\u001b[32m无厘头写手:\n",
      "\n",
      "Solution:  \n",
      "结构提纲（5段）与每段核心句子草案如下，便于后续在总字数300-400字范围内完成成文稿；风格以无厘头科普为主，核心科学事实保持准确。\n",
      "\n",
      "一、结构提纲\n",
      "- 第一段：引子，点题“为什么人会打喷嚏”，以趣味设问或小故事引入。核心要求：激发好奇，奠定喷嚏是生理防御机制的主题。\n",
      "- 第二段：打喷嚏的生理机制。覆盖刺激物、鼻腔黏膜受体、三叉神经、脑干喷嚏中枢的传导路径。\n",
      "- 第三段：喷嚏在生理防御中的意义。强调喷嚏如何清除尘粒、花粉、微生物等，保护呼吸道。\n",
      "- 第四段：创意段落，允许离谱比喻。用生动但科学可核验的比喻来增强趣味性。\n",
      "- 第五段：结论与科普意义。呼应前文，给出日常生活中的科学提示与尊重身体防御的态度。\n",
      "\n",
      "二、每段落的核心句子草案\n",
      "- 第一段核心句子草案：打喷嚏不是偶发的口鼻爆炸，而是鼻腔对侵入者发出的紧急求救信号。\n",
      "- 第二段核心句子草案：刺激物激活鼻腔黏膜感受器，信息经三叉神经传入脑干喷嚏中枢，指令呼吸肌群和发声器官共同发动喷出。\n",
      "- 第三段核心句子草案：喷嚏的主要功能是把尘粒、花粉、微生物等异物迅速清除出鼻腔，阻断进一步进入呼吸道。\n",
      "- 第四段核心句子草案：离谱比喻段落：鼻腔如同繁忙的机场，喷嚏则是一架临时起飞的超音速清洁客机，把外来粒子送回大气层。\n",
      "- 第五段核心句子草案：理解喷嚏的生理机制有助于我们在日常生活中保护鼻腔健康，坦然对待这位“鼻腔卫士”的自我防卫。\n",
      "\n",
      "三、实施与写作要点（可参考，便于控制总字数在300-400字之间）\n",
      "- 字数分配建议（总目标约300-400字）：第一段60-70字，第二段80-100字，第三段60-80字，第四段60-90字，第五段40-60字；五段合计约300-400字。\n",
      "- 语言风格：保持科学准确的同时，适度使用幽默、拟人化和离谱比喻，避免误导性细节。\n",
      "- 关键科学点要点：明确刺激物-受体-三叉神经-喷嚏中枢的传导链；强调喷嚏的排出功能与防御性意义。\n",
      "- 写作提示：段落之间用自然过渡句连接，确保逻辑连贯；在创意段落中明确比喻与生理机制的对应关系，避免断层。\n",
      "\n",
      "Next request.\n",
      "\u001b[34m科学审稿人:\n",
      "\n",
      "Instruction: 请以上述结构提纲为蓝本，完成正式成文稿。要求总字数300-400字，五段式，第一段60-70字，第二段80-100字，第三段60-80字，第四段60-90字，第五段40-60字。保持科学事实准确，适度使用离谱比喻，段落间有自然过渡。 \n",
      "Input: None\n",
      "\u001b[32m无厘头写手:\n",
      "\n",
      "Solution:  \n",
      "打喷嚏不是偶然的口鼻爆炸，而是鼻腔对入侵者发出的紧急求救信号。这信号来自鼻腔的神经网络，像是微型消防广播。一声唤醒，头部肌肉齐心出动。  \n",
      "\n",
      "刺激物进入鼻腔时，鼻腔黏膜的感受器被触发，信息沿着三叉神经传入脑干的喷嚏中枢，随后指令呼吸肌和发声器官协同发力，形成喷嚏的强力吸气、快速呼出与短促的叫喊。  \n",
      "\n",
      "因此，喷嚏的主要功能，是把尘粒、花粉、微生物等异物迅速清除出鼻腔，阻断它们进入呼吸道的路径。清除过程中，喷嚏还会带动黏液与纤毛协作，使残留物更易被排出体外。  \n",
      "\n",
      "离谱段落：鼻腔就像一座繁忙的机场，入境的粒子要先过安检，最终被喷嚏这架临时起飞的超音速清洁客机送回大气层，偶尔还会在机场广播里说“请排队”，其实是让呼气与咳嗽把粒粒逐一遣送。  \n",
      "\n",
      "理解喷嚏的生理机制，能帮助我们保护鼻腔健康：注意过敏原、保持室内清洁，同时以尊重的态度对待这位鼻腔卫士。  \n",
      "Next request.\n",
      "\u001b[34m科学审稿人:\n",
      "\n",
      "Instruction: 请对现有稿件进行润色与结构核对，确保总字数在300-400字之间，并严格按五段分布：第一段60-70字、第二段80-100字、第三段60-80字、第四段60-90字、第五段40-60字；保留核心科学点，完善逻辑衔接与离谱比喻的比例，确保科学事实无误。 \n",
      "Input: None\n",
      "\u001b[32m无厘头写手:\n",
      "\n",
      "Solution:  \n",
      "打喷嚏不是偶然的口鼻爆炸，而是鼻腔对入侵者发出的紧急求救信号。这信号来自鼻腔的神经网络，像是微型消防广播。一声唤醒，头部肌肉齐心出动。  \n",
      "\n",
      "刺激物进入鼻腔时，鼻腔黏膜的感受器被触发，信息沿着三叉神经传入脑干的喷嚏中枢，那里像指挥部把命令下达。随后中枢发出指令，呼吸肌群、胸腹肌与声带协同收缩，先是一口深吸，再快速地喷出，伴随声门短促关闭。  \n",
      "\n",
      "因此，喷嚏的主要功能，是把尘粒、花粉、微生物等异物迅速清除出鼻腔，阻断它们进入呼吸道的路径。清除过程中，黏液和纤毛也协同工作，把残留物更易排出体外。  \n",
      "\n",
      "离谱段落：鼻腔就像一座繁忙的机场，入境粒子要先过安检，喷嚏这架临时起飞的超音速清洁客机就把它们送回大气层，机场广播偶尔提醒“请排队”，其实是让呼气与咳嗽把粒粒逐一遣送。  \n",
      "\n",
      "理解喷嚏的生理机制，能帮助我们保护鼻腔健康，注意过敏原、保持室内清洁，并以尊重的态度对待这位鼻腔卫士的防御。  \n",
      "Next request.\n",
      "\u001b[34m科学审稿人:\n",
      "\n",
      "Instruction: 请对现有稿件进行最终润色与字数核对，确保总字数在300-400字之间并严格按五段分布：第一段60-70字、第二段80-100字、第三段60-80字、第四段60-90字、第五段40-60字；保留核心科学点，完善逻辑衔接与离谱比喻比例，确保科学事实无误。 \n",
      "Input: None\n",
      "\u001b[32m无厘头写手:\n",
      "\n",
      "Solution:  \n",
      "打喷嚏不是偶然的口鼻爆炸，而是鼻腔对入侵者发出的紧急求救信号。这信号来自鼻腔的神经网络，像是微型消防广播。一声唤醒，头部肌肉齐心出动。  \n",
      "\n",
      "刺激物进入鼻腔时，鼻腔黏膜的感受器被触发，信息沿着三叉神经传入脑干的喷嚏中枢，那里像指挥部把命令下达。随后中枢发出指令，呼吸肌群、胸腹肌与声带协同收缩，先是一口深吸，再快速地喷出，伴随声门短促关闭。  \n",
      "\n",
      "因此，喷嚏的主要功能，是把尘粒、花粉、微生物等异物迅速清除出鼻腔，阻断它们进入呼吸道的路径。清除过程中，黏液和纤毛也协同工作，把残留物更易排出体外。  \n",
      "\n",
      "离谱段落：鼻腔就像一座繁忙的机场，入境粒子要先过安检，喷嚏这架临时起飞的超音速清洁客机就把它们送回大气层，机场广播偶尔提醒“请排队”，其实是让呼气与咳嗽把粒粒逐一遣送。  \n",
      "\n",
      "理解喷嚏的生理机制，能帮助我们保护鼻腔健康，注意过敏原、保持室内清洁，并以尊重的态度对待这位鼻腔卫士的防御。  \n",
      "Next request.\n",
      "\u001b[34m科学审稿人:\n",
      "\n",
      "Instruction: 请对现有稿件进行最终字数统计与分段核对，确保总字数在300-400字之间，且五段字数分别落在：第一段60-70字，第二段80-100字，第三段60-80字，第四段60-90字，第五段40-60字；如不符合，请给出一个修改后的版本，且保持核心科学点与离谱比喻的比例。 \n",
      "Input: None\n",
      "\u001b[32m无厘头写手:\n",
      "\n",
      "Solution:  \n",
      "打喷嚏不是偶然的口鼻爆炸，而是鼻腔对入侵者发出的紧急求救信号。这信号来自鼻腔的神经网络，像微型消防广播，一声唤醒，头部肌肉便齐心出动。  \n",
      "\n",
      "刺激物进入鼻腔时，鼻腔黏膜的感受器被触发，信息沿着三叉神经传入脑干喷嚏中枢，那里像指挥部把命令下达。随后中枢发出指令，呼吸肌、胸腹肌与声带协同收缩，先是一口深吸，再迅速喷出，伴随声门短促关闭。  \n",
      "\n",
      "因此，喷嚏的主要功能，是把尘粒、花粉、微生物等异物迅速清除出鼻腔，阻断它们进入呼吸道的路径。清除过程中，黏液和纤毛也协同工作，把残留物更易排出体外。  \n",
      "\n",
      "离谱段落：鼻腔就像一座繁忙的机场，入境粒子要先过安检，喷嚏这架临时起飞的超音速清洁客机就把它们送回大气层，机场广播偶尔提醒“请排队”，其实是让呼气与咳嗽把粒粒逐一遣送。  \n",
      "\n",
      "理解喷嚏的生理机制，能帮助我们保护鼻腔健康，注意过敏原与清洁，并以尊重的态度对待这位鼻腔卫士的防御。  \n",
      "Next request.\n",
      "\u001b[34m科学审稿人:\n",
      "\n",
      "Instruction: 请对现有稿件进行最终润色与字数逐段统计，确保总字数在300-400字之间，五段字数分别落在：第一段60-70字、第二段80-100字、第三段60-80字、第四段60-90字、第五段40-60字；如不符合，请提供一个修改后的版本，确保离谱比喻比例合理且科学点无误。 \n",
      "Input: None\n",
      "\u001b[32m无厘头写手:\n",
      "\n",
      "Solution:  \n",
      "打喷嚏不是偶然的口鼻爆炸，而是鼻腔对入侵者发出的紧急求救信号。这信号源自鼻腔神经网络，仿佛微型消防广播，一声唤醒便让头部与呼吸肌协同起动。  \n",
      "\n",
      "刺激物进入鼻腔时，鼻腔黏膜的感受器被触发，信息沿着三叉神经传入脑干喷嚏中枢，那里像指挥部把命令下达。随后中枢发出指令，呼吸肌、胸腹肌与声带协同收缩，先是一口深吸，再迅速喷出，伴随声门短促关闭。  \n",
      "\n",
      "因此，喷嚏的主要功能，是把尘粒、花粉、微生物等异物迅速清除出鼻腔，阻断它们进入呼吸道的路径。清除过程中，黏液与纤毛协同工作，使残留物更易排出体外。  \n",
      "\n",
      "离谱段落：鼻腔就像一座繁忙的机场，入境粒子要先过安检，喷嚏这架临时起飞的超音速清洁客机把它们送回大气层，机场广播偶尔提醒“请排队”，其实是让呼气与咳嗽把粒粒逐一遣送。  \n",
      "\n",
      "理解喷嚏的生理机制，能帮助我们保护鼻腔健康，注意过敏原与清洁，并以尊重的态度对待这位鼻腔卫士的防御。  \n",
      "Next request.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from colorama import Fore\n",
    "\n",
    "from camel.societies import RolePlaying\n",
    "from camel.utils import print_text_animated\n",
    "from camel.models import OpenAIModel\n",
    "\n",
    "\n",
    "# ========= 你的初始化（原封不动，注意 base_url） =========\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\n",
    "        \"OPENAI_API_KEY not set in environment. Please set it before running this notebook.\"\n",
    "    )\n",
    "\n",
    "base_url = os.getenv(\"OPENAI_API_BASE\", \"https://xiaoai.plus/v1\")\n",
    "model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-5-mini\")\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "\n",
    "# ========= 把你现成的 client 注入 CAMEL（不重新建 client，不换 base_url） =========\n",
    "# 这是“适配器”，不是另一套初始化\n",
    "model = OpenAIModel(\n",
    "    model_type=model_name,\n",
    "    client=client,\n",
    "    model_config_dict=None,  # 不额外配置温度、max_tokens，走 CAMEL 默认\n",
    ")\n",
    "\n",
    "\n",
    "# ========= 更强的 prompts：带评分、硬约束、禁止老套比喻 =========\n",
    "assistant_prompt = \"\"\"\n",
    "你是无厘头科普写手，目标是写出能发表的短文。\n",
    "\n",
    "硬约束\n",
    "1 科学事实必须准确，不能编造机制与因果。\n",
    "2 全文五段，总字数300到400字。\n",
    "3 每段必须有一个清晰的信息点，不允许空搞笑。\n",
    "4 每段至少出现一个具体名词或动作描写，避免抽象空话。\n",
    "\n",
    "风格约束\n",
    "1 无厘头来自比喻与拟人，不来自胡编科学。\n",
    "2 禁止使用“机场”“消防广播”“求救信号”“入侵者”这些现成比喻与表达。\n",
    "3 至少使用两种不同类型的笑点：\n",
    "  a 视觉化比喻\n",
    "  b 反差吐槽或拟人对话\n",
    "\n",
    "输出\n",
    "只输出正文，不输出提纲，不输出解释。\n",
    "\"\"\".strip()\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "你是科学审稿人兼文字编辑。\n",
    "\n",
    "任务分两部分\n",
    "A 事实核查\n",
    "- 用一句话指出是否存在事实风险。\n",
    "- 如有风险，指出具体句子并给出替换句。\n",
    "\n",
    "B 文学与可读性升级\n",
    "- 给出0到10分评分，四项各占2.5分：\n",
    "  1 科学准确\n",
    "  2 信息密度\n",
    "  3 笑点与新鲜感\n",
    "  4 语言节奏与可读性\n",
    "- 必须提出3条可执行改写指令，每条指令格式：\n",
    "  指令：……\n",
    "  目的：……\n",
    "  替换示例：给出1句可直接替换的句子\n",
    "\n",
    "限制\n",
    "不要重复上轮相同的指令。\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# ========= 更有效的 task_prompt：每轮只攻一个维度 =========\n",
    "task_prompt = \"\"\"\n",
    "写一篇无厘头科普短文，主题：为什么人会打喷嚏。\n",
    "要求中文，五段，总字数300到400字，科学事实准确。\n",
    "必须覆盖：刺激物，鼻腔黏膜受体，三叉神经，脑干喷嚏中枢，喷嚏的防御意义。\n",
    "\n",
    "流程\n",
    "1 第一版直接完成成文稿。\n",
    "2 之后每轮只做一种改进，按顺序：\n",
    "  第1轮 优化机制段，压缩但更清楚。\n",
    "  第2轮 更新比喻体系，必须换一套意象，不得复用旧比喻。\n",
    "  第3轮 优化节奏与结尾，读完要有记忆点。\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def run(topic: str = \"为什么人会打喷嚏\", rounds: int = 3) -> None:\n",
    "    rp = RolePlaying(\n",
    "        assistant_role_name=\"无厘头科普写手\",\n",
    "        user_role_name=\"科学审稿人\",\n",
    "        assistant_role_prompt=assistant_prompt,\n",
    "        user_role_prompt=user_prompt,\n",
    "        assistant_agent_kwargs={\"model\": model},\n",
    "        user_agent_kwargs={\"model\": model},\n",
    "        task_prompt=task_prompt.replace(\"为什么人会打喷嚏\", topic),\n",
    "        output_language=\"Chinese\",\n",
    "        with_task_specify=False,\n",
    "        with_critic_in_the_loop=False,\n",
    "    )\n",
    "\n",
    "    print(Fore.YELLOW + \"Task:\\n\" + rp.task_prompt + \"\\n\")\n",
    "\n",
    "    # init_chat 返回 Message 对象或一对 response，按 CAMEL 标准用法传递 msg\n",
    "    input_msg = rp.init_chat()\n",
    "\n",
    "    # 第0轮：生成第一版正文\n",
    "    assistant_response, user_response = rp.step(input_msg)\n",
    "\n",
    "    print_text_animated(Fore.BLUE + \"科学审稿人:\\n\\n\" + user_response.msg.content + \"\\n\")\n",
    "    print_text_animated(Fore.GREEN + \"无厘头写手:\\n\\n\" + assistant_response.msg.content + \"\\n\")\n",
    "\n",
    "    # 后续 rounds：每轮一次审稿一次重写\n",
    "    input_msg = assistant_response.msg\n",
    "    for i in range(rounds):\n",
    "        assistant_response, user_response = rp.step(input_msg)\n",
    "        if user_response.terminated or assistant_response.terminated:\n",
    "            break\n",
    "\n",
    "        print_text_animated(Fore.BLUE + f\"第{i+1}轮审稿:\\n\\n{user_response.msg.content}\\n\")\n",
    "\n",
    "        assistant_response, user_response2 = rp.step(user_response.msg)\n",
    "        if assistant_response.terminated:\n",
    "            break\n",
    "\n",
    "        print_text_animated(Fore.GREEN + f\"第{i+1}轮重写:\\n\\n{assistant_response.msg.content}\\n\")\n",
    "\n",
    "        input_msg = assistant_response.msg\n",
    "\n",
    "    print_text_animated(Fore.YELLOW + \"\\n最终版本:\\n\\n\" + assistant_response.msg.content + \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run(topic=\"为什么人会打喷嚏\", rounds=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
